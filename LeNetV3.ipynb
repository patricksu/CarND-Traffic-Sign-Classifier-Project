{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet for Traffic Sign V3\n",
    "![LeNet Architecture](lenet.png)\n",
    "Modified from source: Yan LeCun\n",
    "\n",
    "Author: Peng \"Patrick\" Su\n",
    "Testing hist_eq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load the traffic sign data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "\n",
    "training_file = '../traffic-signs-data/train.p'\n",
    "validation_file = '../traffic-signs-data/valid.p'\n",
    "testing_file = '../traffic-signs-data/test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The traffic sign data comes as 32x32x3 images, and LeNet accepts 32x32xC images. No need to pad anything. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "Shuffle the training data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    return (img - 128.)/128.\n",
    "def hist_eq(img):\n",
    "    if (len(img.shape)>3): # if you're passing in a collection of images\n",
    "        num_images = img.shape[0]\n",
    "        image_shape = img.shape[1:]\n",
    "        locEqImg = np.zeros([num_images,image_shape[0],image_shape[1],image_shape[2]])\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(6,6))\n",
    "        for i in range(num_images):\n",
    "            #print(\"currImg dtype is \", img[i].dtype)\n",
    "            #img[i] =img[i].astype(np.float32)\n",
    "            currImg = img[i].squeeze()\n",
    "            #img_yuv = cv2.cvtColor(currImg, cv2.COLOR_RGB2YUV)\n",
    "            #img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "            #tmp = cv2.cvtColor(img_yuv, cv 2.COLOR_YUV2RGB)\n",
    "            #eqImg[i]=tmp\n",
    "            \n",
    "            img_lab = cv2.cvtColor(currImg, cv2.COLOR_RGB2LAB)\n",
    "            img_lab[:,:,0]=clahe.apply(img_lab[:,:,0])\n",
    "            tmp = cv2.cvtColor(img_lab, cv2.COLOR_LAB2RGB)\n",
    "            locEqImg[i] = tmp\n",
    "    else:\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(6,6))\n",
    "        img_lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "        img_lab[:,:,0]=clahe.apply(img_lab[:,:,0])\n",
    "        tmp = cv2.cvtColor(img_lab, cv2.COLOR_LAB2RGB)\n",
    "        locEqImg = tmp\n",
    "    return locEqImg\n",
    "\n",
    "X_train = hist_eq(X_train)\n",
    "X_train = normalize(X_train)\n",
    "X_train = X_train.astype('float32')\n",
    "\n",
    "X_valid = hist_eq(X_valid)\n",
    "X_valid = normalize(X_valid)\n",
    "X_valid = X_valid.astype('float32')\n",
    "\n",
    "X_test = hist_eq(X_test)\n",
    "X_test = normalize(X_test)\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34799, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup TensorFlow\n",
    "The `EPOCH` and `BATCH_SIZE` values affect the training speed and model accuracy.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Implement LeNet-5\n",
    "Implement the [LeNet-5](http://yann.lecun.com/exdb/lenet/) neural network architecture.\n",
    "\n",
    "This is the only cell you need to edit.\n",
    "### Input\n",
    "The LeNet architecture accepts a 32x32xC image as input, where C is the number of color channels. Since MNIST images are grayscale, C is 1 in this case.\n",
    "\n",
    "### Architecture\n",
    "**Layer 1: Convolutional.** The output shape should be 28x28x6.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 14x14x6.\n",
    "\n",
    "**Layer 2: Convolutional.** The output shape should be 10x10x16.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 5x5x16.\n",
    "\n",
    "**Flatten.** Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. The easiest way to do is by using `tf.contrib.layers.flatten`, which is already imported for you.\n",
    "\n",
    "**Layer 3: Fully Connected.** This should have 120 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 4: Fully Connected.** This should have 84 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 5: Fully Connected (Logits).** This should have 10 outputs.\n",
    "\n",
    "### Output\n",
    "Return the result of the 2nd fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    weights = {\n",
    "        'wc1': tf.Variable(tf.truncated_normal([5,5,3,6], mu, sigma)),\n",
    "        'wc2': tf.Variable(tf.truncated_normal([5,5,6,16], mu, sigma)),\n",
    "        'wf3': tf.Variable(tf.truncated_normal([5*5*16, 120], mu, sigma)),\n",
    "        'wf4': tf.Variable(tf.truncated_normal([120, 84], mu, sigma)),\n",
    "        'wf5': tf.Variable(tf.truncated_normal([84, 43], mu, sigma))}\n",
    "    biases = {\n",
    "        'bc1': tf.zeros([6]),\n",
    "        'bc2': tf.zeros([16]),\n",
    "        'bf3': tf.zeros([120]),\n",
    "        'bf4': tf.zeros([84]),\n",
    "        'bf5': tf.zeros([43]),\n",
    "    }\n",
    "    # TODO: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    conv1 = tf.nn.conv2d(x, weights['wc1'], strides = [1, 1, 1, 1], padding = 'VALID')\n",
    "    conv1 = tf.nn.bias_add(conv1, biases['bc1'])\n",
    "    # TODO: Activation.\n",
    "    conv1 = tf.nn.relu(conv1)    \n",
    "    # TODO: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'VALID')\n",
    "    conv1 = tf.nn.dropout(conv1, keep_prob)\n",
    "#     flat1 = flatten(conv1, [-1, 14*14*6])\n",
    "    \n",
    "    # TODO: Layer 2: Convolutional. Output = 10x10x16.\n",
    "    conv2 = tf.nn.conv2d(conv1, weights['wc2'], strides = [1, 1, 1, 1], padding = 'VALID')\n",
    "    conv2 = tf.nn.bias_add(conv2, biases['bc2'])    \n",
    "    # TODO: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    # TODO: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'VALID')\n",
    "    conv2 = tf.nn.dropout(conv2, keep_prob)\n",
    "    # TODO: Flatten. Input = 5x5x8. Output = 200.\n",
    "\n",
    "#     flat2 = flatten(conv2, [-1, 5*5*16])\n",
    "#     flat = tf.concat(1, [flat1, flat2])\n",
    "    \n",
    "    flat = flatten(conv2, [-1, 5*5*16])\n",
    "    \n",
    "    # TODO: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    fc3 = tf.add(tf.matmul(flat, weights['wf3']), biases['bf3'])\n",
    "    # TODO: Activation.\n",
    "    fc3 = tf.nn.relu(fc3)\n",
    "    # TODO: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc4 = tf.add(tf.matmul(fc3, weights['wf4']), biases['bf4'])\n",
    "    # TODO: Activation.\n",
    "    fc4 = tf.nn.relu(fc4)\n",
    "    # TODO: Layer 5: Fully Connected. Input = 84. Output = 43.\n",
    "    logits = tf.add(tf.matmul(fc4, weights['wf5']), biases['bf5'])\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Labels\n",
    "Train LeNet to classify traffic sign data.\n",
    "\n",
    "`x` is a placeholder for a batch of input images.\n",
    "`y` is a placeholder for a batch of output labels.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 43)\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline\n",
    "Create a training pipeline that uses the model to classify MNIST data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rate = 0.001\n",
    "logits = LeNet(x)\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluate how well the loss and accuracy of the model for a given dataset.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    total_loss = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        loss, accuracy = sess.run([loss_operation, accuracy_operation], feed_dict={x: batch_x, y: batch_y, keep_prob:1.0})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "        total_loss += (loss * len(batch_x))\n",
    "    return total_loss / num_examples, total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "Run the training data through the training pipeline to train the model.\n",
    "\n",
    "Before each epoch, shuffle the training set.\n",
    "\n",
    "After each epoch, measure the loss and accuracy of the validation set.\n",
    "\n",
    "Save the model after training.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "save_dir = 'LeNetV3'\n",
    "out_dir = out_dir = os.path.abspath(os.path.join(os.path.curdir, \"../Traffic-Sign-Classifier-runs\", save_dir))\n",
    "if os.path.exists(out_dir):\n",
    "    shutil.rmtree(out_dir)\n",
    "train_summary_dir = os.path.join(out_dir, \"train\")        \n",
    "valid_summary_dir = os.path.join(out_dir, \"valid\")\n",
    "checkpoint_dir = os.path.join(out_dir, \"checkpoints\")\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir,\"model\")\n",
    "checkpoint_every = 100\n",
    "train_summary_every = 100\n",
    "valid_summary_every = 100\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "Batch 100 Train Loss: 1.231 Train Accuracy: 0.648\n",
      "\n",
      "valid writing\n",
      "EPOCH 1 Batch 100 ...\n",
      "Validation loss = 1.338\n",
      "Validation Accuracy = 0.620\n",
      "\n",
      "Batch 200 Train Loss: 0.433 Train Accuracy: 0.859\n",
      "\n",
      "valid writing\n",
      "EPOCH 1 Batch 200 ...\n",
      "Validation loss = 0.650\n",
      "Validation Accuracy = 0.801\n",
      "\n",
      "Batch 300 Train Loss: 0.289 Train Accuracy: 0.938\n",
      "\n",
      "valid writing\n",
      "EPOCH 2 Batch 300 ...\n",
      "Validation loss = 0.457\n",
      "Validation Accuracy = 0.879\n",
      "\n",
      "Batch 400 Train Loss: 0.273 Train Accuracy: 0.938\n",
      "\n",
      "valid writing\n",
      "EPOCH 2 Batch 400 ...\n",
      "Validation loss = 0.354\n",
      "Validation Accuracy = 0.910\n",
      "\n",
      "Batch 500 Train Loss: 0.202 Train Accuracy: 0.953\n",
      "\n",
      "valid writing\n",
      "EPOCH 2 Batch 500 ...\n",
      "Validation loss = 0.346\n",
      "Validation Accuracy = 0.896\n",
      "\n",
      "Batch 600 Train Loss: 0.119 Train Accuracy: 0.969\n",
      "\n",
      "valid writing\n",
      "EPOCH 3 Batch 600 ...\n",
      "Validation loss = 0.310\n",
      "Validation Accuracy = 0.923\n",
      "\n",
      "Batch 700 Train Loss: 0.117 Train Accuracy: 0.969\n",
      "\n",
      "valid writing\n",
      "EPOCH 3 Batch 700 ...\n",
      "Validation loss = 0.306\n",
      "Validation Accuracy = 0.923\n",
      "\n",
      "Batch 800 Train Loss: 0.109 Train Accuracy: 0.977\n",
      "\n",
      "valid writing\n",
      "EPOCH 3 Batch 800 ...\n",
      "Validation loss = 0.264\n",
      "Validation Accuracy = 0.935\n",
      "\n",
      "Batch 900 Train Loss: 0.047 Train Accuracy: 0.984\n",
      "\n",
      "valid writing\n",
      "EPOCH 4 Batch 900 ...\n",
      "Validation loss = 0.268\n",
      "Validation Accuracy = 0.942\n",
      "\n",
      "Batch 1000 Train Loss: 0.039 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 4 Batch 1000 ...\n",
      "Validation loss = 0.242\n",
      "Validation Accuracy = 0.938\n",
      "\n",
      "Batch 1100 Train Loss: 0.108 Train Accuracy: 0.961\n",
      "\n",
      "valid writing\n",
      "EPOCH 5 Batch 1100 ...\n",
      "Validation loss = 0.248\n",
      "Validation Accuracy = 0.946\n",
      "\n",
      "Batch 1200 Train Loss: 0.058 Train Accuracy: 0.984\n",
      "\n",
      "valid writing\n",
      "EPOCH 5 Batch 1200 ...\n",
      "Validation loss = 0.227\n",
      "Validation Accuracy = 0.949\n",
      "\n",
      "Batch 1300 Train Loss: 0.025 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 5 Batch 1300 ...\n",
      "Validation loss = 0.247\n",
      "Validation Accuracy = 0.938\n",
      "\n",
      "Batch 1400 Train Loss: 0.152 Train Accuracy: 0.969\n",
      "\n",
      "valid writing\n",
      "EPOCH 6 Batch 1400 ...\n",
      "Validation loss = 0.218\n",
      "Validation Accuracy = 0.952\n",
      "\n",
      "Batch 1500 Train Loss: 0.050 Train Accuracy: 0.984\n",
      "\n",
      "valid writing\n",
      "EPOCH 6 Batch 1500 ...\n",
      "Validation loss = 0.215\n",
      "Validation Accuracy = 0.946\n",
      "\n",
      "Batch 1600 Train Loss: 0.044 Train Accuracy: 0.984\n",
      "\n",
      "valid writing\n",
      "EPOCH 6 Batch 1600 ...\n",
      "Validation loss = 0.210\n",
      "Validation Accuracy = 0.947\n",
      "\n",
      "Batch 1700 Train Loss: 0.015 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 7 Batch 1700 ...\n",
      "Validation loss = 0.219\n",
      "Validation Accuracy = 0.951\n",
      "\n",
      "Batch 1800 Train Loss: 0.038 Train Accuracy: 0.984\n",
      "\n",
      "valid writing\n",
      "EPOCH 7 Batch 1800 ...\n",
      "Validation loss = 0.205\n",
      "Validation Accuracy = 0.951\n",
      "\n",
      "Batch 1900 Train Loss: 0.045 Train Accuracy: 0.984\n",
      "\n",
      "valid writing\n",
      "EPOCH 7 Batch 1900 ...\n",
      "Validation loss = 0.226\n",
      "Validation Accuracy = 0.956\n",
      "\n",
      "Batch 2000 Train Loss: 0.016 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 8 Batch 2000 ...\n",
      "Validation loss = 0.217\n",
      "Validation Accuracy = 0.956\n",
      "\n",
      "Batch 2100 Train Loss: 0.022 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 8 Batch 2100 ...\n",
      "Validation loss = 0.220\n",
      "Validation Accuracy = 0.950\n",
      "\n",
      "Batch 2200 Train Loss: 0.034 Train Accuracy: 0.984\n",
      "\n",
      "valid writing\n",
      "EPOCH 9 Batch 2200 ...\n",
      "Validation loss = 0.224\n",
      "Validation Accuracy = 0.953\n",
      "\n",
      "Batch 2300 Train Loss: 0.014 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 9 Batch 2300 ...\n",
      "Validation loss = 0.220\n",
      "Validation Accuracy = 0.954\n",
      "\n",
      "Batch 2400 Train Loss: 0.018 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 9 Batch 2400 ...\n",
      "Validation loss = 0.186\n",
      "Validation Accuracy = 0.956\n",
      "\n",
      "Batch 2500 Train Loss: 0.012 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 10 Batch 2500 ...\n",
      "Validation loss = 0.228\n",
      "Validation Accuracy = 0.958\n",
      "\n",
      "Batch 2600 Train Loss: 0.033 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 10 Batch 2600 ...\n",
      "Validation loss = 0.174\n",
      "Validation Accuracy = 0.961\n",
      "\n",
      "Batch 2700 Train Loss: 0.026 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 10 Batch 2700 ...\n",
      "Validation loss = 0.222\n",
      "Validation Accuracy = 0.958\n",
      "\n",
      "Batch 2800 Train Loss: 0.004 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 11 Batch 2800 ...\n",
      "Validation loss = 0.189\n",
      "Validation Accuracy = 0.960\n",
      "\n",
      "Batch 2900 Train Loss: 0.027 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 11 Batch 2900 ...\n",
      "Validation loss = 0.226\n",
      "Validation Accuracy = 0.951\n",
      "\n",
      "Batch 3000 Train Loss: 0.013 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 12 Batch 3000 ...\n",
      "Validation loss = 0.190\n",
      "Validation Accuracy = 0.961\n",
      "\n",
      "Batch 3100 Train Loss: 0.012 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 12 Batch 3100 ...\n",
      "Validation loss = 0.181\n",
      "Validation Accuracy = 0.957\n",
      "\n",
      "Batch 3200 Train Loss: 0.020 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 12 Batch 3200 ...\n",
      "Validation loss = 0.189\n",
      "Validation Accuracy = 0.962\n",
      "\n",
      "Batch 3300 Train Loss: 0.025 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 13 Batch 3300 ...\n",
      "Validation loss = 0.206\n",
      "Validation Accuracy = 0.959\n",
      "\n",
      "Batch 3400 Train Loss: 0.012 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 13 Batch 3400 ...\n",
      "Validation loss = 0.196\n",
      "Validation Accuracy = 0.957\n",
      "\n",
      "Batch 3500 Train Loss: 0.024 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 13 Batch 3500 ...\n",
      "Validation loss = 0.205\n",
      "Validation Accuracy = 0.961\n",
      "\n",
      "Batch 3600 Train Loss: 0.026 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 14 Batch 3600 ...\n",
      "Validation loss = 0.167\n",
      "Validation Accuracy = 0.967\n",
      "\n",
      "Batch 3700 Train Loss: 0.008 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 14 Batch 3700 ...\n",
      "Validation loss = 0.183\n",
      "Validation Accuracy = 0.959\n",
      "\n",
      "Batch 3800 Train Loss: 0.012 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 14 Batch 3800 ...\n",
      "Validation loss = 0.198\n",
      "Validation Accuracy = 0.957\n",
      "\n",
      "Batch 3900 Train Loss: 0.010 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 15 Batch 3900 ...\n",
      "Validation loss = 0.217\n",
      "Validation Accuracy = 0.958\n",
      "\n",
      "Batch 4000 Train Loss: 0.006 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 15 Batch 4000 ...\n",
      "Validation loss = 0.141\n",
      "Validation Accuracy = 0.962\n",
      "\n",
      "Batch 4100 Train Loss: 0.008 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 16 Batch 4100 ...\n",
      "Validation loss = 0.158\n",
      "Validation Accuracy = 0.959\n",
      "\n",
      "Batch 4200 Train Loss: 0.018 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 16 Batch 4200 ...\n",
      "Validation loss = 0.160\n",
      "Validation Accuracy = 0.961\n",
      "\n",
      "Batch 4300 Train Loss: 0.008 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 16 Batch 4300 ...\n",
      "Validation loss = 0.174\n",
      "Validation Accuracy = 0.960\n",
      "\n",
      "Batch 4400 Train Loss: 0.042 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 17 Batch 4400 ...\n",
      "Validation loss = 0.169\n",
      "Validation Accuracy = 0.965\n",
      "\n",
      "Batch 4500 Train Loss: 0.036 Train Accuracy: 0.984\n",
      "\n",
      "valid writing\n",
      "EPOCH 17 Batch 4500 ...\n",
      "Validation loss = 0.211\n",
      "Validation Accuracy = 0.962\n",
      "\n",
      "Batch 4600 Train Loss: 0.006 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 17 Batch 4600 ...\n",
      "Validation loss = 0.186\n",
      "Validation Accuracy = 0.956\n",
      "\n",
      "Batch 4700 Train Loss: 0.017 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 18 Batch 4700 ...\n",
      "Validation loss = 0.177\n",
      "Validation Accuracy = 0.966\n",
      "\n",
      "Batch 4800 Train Loss: 0.018 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 18 Batch 4800 ...\n",
      "Validation loss = 0.166\n",
      "Validation Accuracy = 0.964\n",
      "\n",
      "Batch 4900 Train Loss: 0.016 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 19 Batch 4900 ...\n",
      "Validation loss = 0.186\n",
      "Validation Accuracy = 0.964\n",
      "\n",
      "Batch 5000 Train Loss: 0.016 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 19 Batch 5000 ...\n",
      "Validation loss = 0.149\n",
      "Validation Accuracy = 0.968\n",
      "\n",
      "Batch 5100 Train Loss: 0.010 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 19 Batch 5100 ...\n",
      "Validation loss = 0.202\n",
      "Validation Accuracy = 0.961\n",
      "\n",
      "Batch 5200 Train Loss: 0.002 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 20 Batch 5200 ...\n",
      "Validation loss = 0.143\n",
      "Validation Accuracy = 0.966\n",
      "\n",
      "Batch 5300 Train Loss: 0.016 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 20 Batch 5300 ...\n",
      "Validation loss = 0.151\n",
      "Validation Accuracy = 0.965\n",
      "\n",
      "Batch 5400 Train Loss: 0.015 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 20 Batch 5400 ...\n",
      "Validation loss = 0.147\n",
      "Validation Accuracy = 0.965\n",
      "\n",
      "Training Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    global_step = 0\n",
    "    train_summary_writer = tf.summary.FileWriter(train_summary_dir, sess.graph)\n",
    "    valid_summary_writer = tf.summary.FileWriter(valid_summary_dir, sess.graph)\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob:0.8})\n",
    "            global_step += 1\n",
    "            if global_step % train_summary_every == 0:\n",
    "                train_loss, train_accuracy = evaluate(batch_x, batch_y)\n",
    "                train_summaries = tf.Summary()\n",
    "                train_summaries.value.add(tag='Train Loss', simple_value=train_loss)\n",
    "                train_summaries.value.add(tag='Train Accuracy', simple_value=train_accuracy)\n",
    "                train_summary_writer.add_summary(train_summaries, global_step)\n",
    "                print(\"Batch {} Train Loss: {:.3f} Train Accuracy: {:.3f}\".format(global_step, train_loss, train_accuracy))\n",
    "                print()\n",
    "            if global_step % valid_summary_every == 0:\n",
    "                validation_loss, validation_accuracy = evaluate(X_valid, y_valid)\n",
    "                valid_summaries = tf.Summary()\n",
    "                valid_summaries.value.add(tag='Validation Loss', simple_value=validation_loss)\n",
    "                valid_summaries.value.add(tag='Validation Accuracy', simple_value=validation_accuracy)\n",
    "                print(\"valid writing\")\n",
    "                valid_summary_writer.add_summary(valid_summaries, global_step)\n",
    "                print(\"EPOCH {} Batch {} ...\".format(i+1, global_step))\n",
    "                print(\"Validation loss = {:.3f}\".format(validation_loss))\n",
    "                print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "                print()\n",
    "            if global_step % checkpoint_every == 0:\n",
    "                saver.save(sess, checkpoint_prefix, global_step=global_step)            \n",
    "    print(\"Training Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "Once you are completely satisfied with your model, evaluate the performance of the model on the test set.\n",
    "\n",
    "Be sure to only do this once!\n",
    "\n",
    "If you were to measure the performance of your trained model on the test set, then improve your model, and then measure the performance of your model on the test set again, that would invalidate your test results. You wouldn't get a true measure of how well your model would perform against real data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.010\n",
      "Train Accuracy = 0.998\n",
      "Valid Loss = 0.147\n",
      "Valid Accuracy = 0.965\n",
      "Test Loss = 0.171\n",
      "Test Accuracy = 0.956\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    train_loss, train_accuracy = evaluate(X_train, y_train)\n",
    "    print(\"Train Loss = {:.3f}\".format(train_loss))\n",
    "    print(\"Train Accuracy = {:.3f}\".format(train_accuracy))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    valid_loss, valid_accuracy = evaluate(X_valid, y_valid)\n",
    "    print(\"Valid Loss = {:.3f}\".format(valid_loss))\n",
    "    print(\"Valid Accuracy = {:.3f}\".format(valid_accuracy))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    test_loss, test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Loss = {:.3f}\".format(test_loss))\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corr_predict(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    corr_predict = np.zeros(num_examples)\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        temp = np.array(sess.run([correct_prediction], feed_dict={x: batch_x, y: batch_y, keep_prob:1.0})).astype('Int32')\n",
    "        corr_predict[offset:offset+BATCH_SIZE] = temp\n",
    "    return corr_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    corr_pred = corr_predict(X_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f27216f99e8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3YAAAE7CAYAAACR9BMWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X+UlPV9L/DP/sAc2CXI/hRWEFkltVaxJx49ikcJqJgY\nKj+U5kfVQq/Ue1WUGK1i06RSNcVYaWOvkcbG02hMvQh6kaRW1hCMBBNtFXsixyiOKBFYdlfCL4Wd\nfe4fXrdRFliRmWee5fX6C2aH+bx5Zua7z3tmnnnKkiRJAgAAgMwqTzsAAAAAH49iBwAAkHGKHQAA\nQMYpdgAAABmn2AEAAGScYgcAAJBxlYW88V27dsWXv/zl2L17d+Tz+ZgwYUJceeWVsWXLlpg9e3as\nX78+jjzyyJg/f34MHDiwkFEAAAD6rLJCn8du586d0b9//8jn8/HFL34x/vIv/zIef/zxOPzww+Oy\nyy6LBQsWxG9/+9v46le/WsgYAAAAfVbBP4rZv3//iHjv3bvOzs6IiGhpaYnJkydHRMTkyZNj2bJl\nhY4BAADQZxW82HV1dcWkSZNizJgxMWbMmDjxxBOjra0t6urqIiKivr4+2tvbCx0DAACgzyp4sSsv\nL49HHnkkVqxYEatXr45f//rXUVZW9oHrfPjvAAAA9F7RvhWzuro6TjnllHjqqaeitrY2Nm/eHBER\nra2tUVNTs99/39mZL3REAACATCrot2K2t7dHv379YuDAgfHOO+/EypUrY+bMmTFu3LhYtGhRzJw5\nMxYvXhzjx4/f7211dOwoZFQAAICSVl+/9zMJFLTYtba2xg033BBdXV3R1dUVn/vc5+Kss86K0aNH\nxzXXXBMPP/xwNDU1xfz58wsZAwAAoE8r+OkODpbW1q1pRwAAAEjNvt6xK9oxdgAAABSGYgcAAJBx\nih0AAEDGKXYAAAAZp9gBAABknGIHAACQcYodAABAxil2AAAAGafYAQAAZJxiBwAAkHGKHQAAQMYp\ndgAAABmn2AEAAGRcZdoBAA4l+Xw+crm1qc0fMWJkVFRUpDYfACgMxQ6giHK5tXHlv30tBjQMLPrs\nHZu2xl3nzY3m5mOLPhsAKCzFDqDIBjQMjKqmw9OOAQD0IY6xAwAAyDjFDgAAIOMUOwAAgIxT7AAA\nADJOsQMAAMg4xQ4AACDjFDsAAICMU+wAAAAyTrEDAADIOMUOAAAg4xQ7AACAjFPsAAAAMk6xAwAA\nyDjFDgAAIOMUOwAAgIxT7AAAADJOsQMAAMg4xQ4AACDjFDsAAICMU+wAAAAyTrEDAADIOMUOAAAg\n4yoLeeMbNmyI66+/Ptra2qK8vDymTZsWF198cdx1113x0EMPRW1tbUREzJ49O84888xCRgEAAOiz\nClrsKioq4sYbb4zjjjsutm/fHlOmTInTTz89IiKmT58e06dPL+R4AACAQ0JBi119fX3U19dHRERV\nVVU0NzfHpk2bIiIiSZJCjgYAADhkFO0YuzfffDPWrFkTJ554YkRE3H///XHBBRfETTfdFFu3bi1W\nDAAAgD6noO/YvW/79u0xa9asmDNnTlRVVcWXvvSluOKKK6KsrCzuvPPOuO222+LWW2/d520MHjwg\nKisrihEXoGA6OqpTnV9TUx319QNTzQAAHHwFL3adnZ0xa9asuOCCC+Lss8+OiIiamprun0+bNi0u\nv/zy/d5OR8eOgmUEKJb29m2pz29t9SkJAMiifb04W/CPYs6ZMyeOOeaYuPTSS7sva21t7f7zE088\nEaNGjSp0DAAAgD6roO/YPffcc7FkyZIYNWpUTJo0KcrKymL27Nnx2GOPxUsvvRTl5eXR1NQUN998\ncyFjAAAA9GkFLXaf/vSn46WXXtrjcuesAwAAOHiK9q2YAAAAFIZiBwAAkHGKHQAAQMYpdgAAABmn\n2AEAAGScYgcAAJBxih0AAEDGKXYAAAAZp9gBAABknGIHAACQcYodAABAxil2AAAAGafYAQAAZJxi\nBwAAkHGKHQAAQMYpdgAAABmn2AEAAGScYgcAAJBxih0AAEDGKXYAAAAZp9gBAABknGIHAACQcYod\nAABAxil2AAAAGafYAQAAZJxiBwAAkHGKHQAAQMYpdgAAABmn2AEAAGScYgcAAJBxih0AAEDGKXYA\nAAAZV5l2AACANOTz+cjl1qY2f8SIkVFRUZHafKBvUewAgENSLrc2rlv6y6hqaCr67O2b1sft50c0\nNx9b9NlA36TYAQCHrKqGphg4dETaMQA+NsfYAQAAZJxiBwAAkHEF/Sjmhg0b4vrrr4+2trYoLy+P\niy66KC655JLYsmVLzJ49O9avXx9HHnlkzJ8/PwYOHFjIKAAAAH1WQd+xq6ioiBtvvDGWLl0aP/zh\nD+OBBx6IV199NRYsWBCnnXZaPP7443HqqafGPffcU8gYAAAAfVpBi119fX0cd9xxERFRVVUVzc3N\nsXHjxmhpaYnJkydHRMTkyZNj2bJlhYwBAADQpxXtGLs333wz1qxZE6NHj462traoq6uLiPfKX3t7\ne7FiAAAA9DlFKXbbt2+PWbNmxZw5c6KqqirKyso+8PMP/x0AAIDeK/h57Do7O2PWrFlxwQUXxNln\nnx0REbW1tbF58+aoq6uL1tbWqKmp2e/tDB48ICorKwodF6CgOjqqU51fU1Md9fW+rAoiPB+BvqXg\nxW7OnDlxzDHHxKWXXtp92bhx42LRokUxc+bMWLx4cYwfP36/t9PRsaOQMQGKor19W+rzW1u3ppoB\nSoXnI5A1+3oxqKAfxXzuuediyZIlsWrVqpg0aVJMnjw5VqxYEZdddlmsXLkyJkyYEKtWrYqZM2cW\nMgYAAECfVtB37D796U/HSy+91OPP7rvvvkKOBgAAOGQU7VsxAQAAKAzFDgAAIOMUOwAAgIxT7AAA\nADJOsQMAAMg4xQ4AACDjFDsAAICMU+wAAAAyTrEDAADIOMUOAAAg4xQ7AACAjFPsAAAAMk6xAwAA\nyDjFDgAAIOMUOwAAgIxT7AAAADJOsQMAAMg4xQ4AACDjFDsAAICMU+wAAAAyTrEDAADIOMUOAAAg\n4xQ7AACAjKtMO0Bfks/nI5dbm8rsESNGRkVFRSqzAQCAdCl2B1EutzZyD9wVw2sHF3XuuraOiC9f\nGc3NxxZ1LgAAUBoUu4NseO3gaG6sTzsGAABwCHGMHQAAQMYpdgAAABmn2AEAAGRcr4rd1Vdf3avL\nAAAAKL5eFbt169btcdnatel8rT8AAAAftM9vxXzooYfiX//1XyOXy8WFF17YffnWrVvj6KOPLng4\nAAAA9m+fxW7MmDFx1FFHxdy5c+P666/vvry6ujo+9alPFTwcAABAmvL5fORy6XxaccSIkVFRUdGr\n6+6z2DU1NUVTU1M89thjByUYAABAluRya+P17/84htc2FnXuuraNERd/Npqbj+3V9Xt1gvK1a9fG\n3XffHW+88UZ0dnZ2X75w4cIDSwkAAJARw2sbo7nhyLRj7FOvit1XvvKVOO+882LKlCm9fisQAACA\n4uhVsevq6orLL7+80FkAAAA4AL063cFJJ50Ua9asKXQWAAAADkCv3rFbvXp1LFq0KI4++uj4xCc+\n0X35/o6xmzNnTixfvjxqa2tjyZIlERFx1113xUMPPRS1tbURETF79uw488wzDzQ/AADAIa9XxW7O\nnDkHdONTpkyJiy+++AOnSoiImD59ekyfPv2AbhMAAIAP6lWxO+WUUw7oxk8++eRYv379HpcnSXJA\ntwcAAMCeelXspk6dGmVlZXtcfqCnO7j//vvj0UcfjT/4gz+IG264IQYOHHhAtwMAAEAvi91f/MVf\ndP/53XffjaVLl0ZDQ8MBDfzSl74UV1xxRZSVlcWdd94Zt912W9x66637/XeDBw+IysrSPtVCR0d1\nbE5pdk1NddTXK8hQ6jo6qlOdb62A/+b5CPRGR0d1tKU0+6OsEwf0UcwzzjgjvvjFL370ZBFRU1PT\n/edp06b1+jQKHR07DmheMbW3b0t1dmvr1tTmA72T5jrx/nxrBbzH8xHojVLax99XyevV6Q4+bNu2\nbbF5c+/em/rw8XStra3df37iiSdi1KhRBxIBAACA/+8jH2PX1dUVb775Zq++1fLaa6+NZ555Jt5+\n++0YO3ZsXHXVVfHMM8/ESy+9FOXl5dHU1BQ333zzx/sfAAAAHOI+8jF2FRUVMWzYsF4dY3fHHXfs\ncdnUqVM/QjwAAAD2p9fH2HV2dsZrr70WER88Tg4AAIB09arYvfjiizFr1qw47LDDIkmS6OzsjG9/\n+9tx/PHHFzofAAAA+9GrYnfLLbfErbfeGqeddlpERPz85z+PuXPnxg9/+MOChgMAAGD/evWtmDt3\n7uwudRERp512WuzcubNgoQAAAOi9Xr1j179//3jmmWfi1FNPjYiIX/ziF9G/f/+CBgOAUpXP5yOX\nW5va/BEjRkZFRUVq8wEoPb0qdjfddFP3MXYREbt3745/+Id/KGgwAChVudzauPqxf43+DfVFn71z\nU2v8/ef/OJqbjy36bABKV6+K3datW2PhwoXR1tYWERG1tbXx8ssvFzQYAJSy/g31UT10SNoxACAi\nenmM3bx586KmpiZGjRoVo0aNisGDB8e8efMKnQ0AAIBe6FWxS5IkysrK/vsflZdHPp8vWCgAAAB6\nr1fFrqqqKl544YXuv7/wwgsxYMCAgoUCAACg93p1jN11110XV1xxRRxzzDEREfHKK6/EXXfdVdBg\nAAAA9E6vit0f/uEfxtKlS+P555+PiIiTTjopBg0aVNBgAAAA9E6vil1ExKBBg+Kss84qZBYAAAAO\nQK+OsQMAAKB0KXYAAAAZp9gBAABknGIHAACQcYodAABAxil2AAAAGafYAQAAZJxiBwAAkHGKHQAA\nQMYpdgAAABmn2AEAAGScYgcAAJBxih0AAEDGKXYAAAAZp9gBAABknGIHAACQcYodAABAxil2AAAA\nGafYAQAAZJxiBwAAkHGKHQAAQMYpdgAAABmn2AEAAGScYgcAAJBxBS12c+bMidNPPz0mTpzYfdmW\nLVtixowZMWHChPizP/uz2Lp1ayEjAAAA9HkFLXZTpkyJe++99wOXLViwIE477bR4/PHH49RTT417\n7rmnkBEAAAD6vIIWu5NPPjk++clPfuCylpaWmDx5ckRETJ48OZYtW1bICAAAAH1e0Y+xa29vj7q6\nuoiIqK+vj/b29mJHAAAA6FNS//KUsrKytCMAAABkWmWxB9bW1sbmzZujrq4uWltbo6amplf/bvDg\nAVFZWVHgdB9PR0d1bE5pdk1NddTXD0xpOtBbHR3Vqc63Vhwc7se+wf0I9EZHR3W0pTT7o6wTBS92\nSZJ84O/jxo2LRYsWxcyZM2Px4sUxfvz4Xt1OR8eOQsQ7qNrbt6U6u7XVN4xCqUtznXh/vrXi43M/\n9g3uR6A3Smkff18lr6Afxbz22mvjC1/4Qrz22msxduzYePjhh2PmzJmxcuXKmDBhQqxatSpmzpxZ\nyAgAAAB9XkHfsbvjjjt6vPy+++4r5FgAAIBDSupfngIAAMDHo9gBAABknGIHAACQcYodAABAxhX9\nPHYAAAAfls/nI5dbm8rsESNGRkVFaZ8ze38UOwAAIHW53NrI3fezGF4ztKhz17X/JuJPI5qbjy3q\n3INNsQMAAErC8Jqh0dwwPO0YmeQYOwAAgIxT7AAAADJOsQMAAMg4xQ4AACDjFDsAAICMU+wAAAAy\nTrEDAADIOMUOAAAg4xQ7AACAjFPsAAAAMk6xAwAAyDjFDgAAIOMUOwAAgIxT7AAAADJOsQMAAMg4\nxQ4AACDjKtMOAAB7k8/nI5dbm9r8ESNGRkVFRWrzAaC3FDsASlYutzZmLb0v+jfUFX32zk2b4x/O\n/9Nobj626LMB4KNS7AAoaf0b6qJ6aGPaMQCgpDnGDgAAIOMUOwAAgIxT7AAAADJOsQMAAMg4xQ4A\nACDjFDsAAICMU+wAAAAyTrEDAADIOMUOAAAg4xQ7AACAjFPsAAAAMk6xAwAAyLjKtAaPGzcuqqur\no7y8PCorK2PhwoVpRQEAAMi01IpdWVlZfP/7349BgwalFQEAAKBPSO2jmEmSRFdXV1rjAQAA+oxU\n37GbMWNGlJeXxx//8R/HtGnT0ooCfAz5fD5yubWpzB4xYmRUVFSkMhvovTTXiQhrxcFSyvej30WQ\nYrF78MEHo6GhIdrb22P69OkxcuTIOPnkk/d6/cGDB0RlZWk/aTo6qmNzSrNraqqjvn5gStM5lL38\n8svxvUcui5r6/kWd2966M66d8WCMGjWqqHM/ro6O6lTnZ22tKNXtVaq5StXLL78cX1m6LKoahhR9\n9vZNb8V9F0/qca1wP340L7/8cvzfpa9EQ8NRRZ+9adPr8acXV+91zX/55ZfjZw//OobUFzfbW62v\nR81le8/FR1Oq+9IdHdXRVuQ87/so60Rqxa6hoSEiImpqauKcc86JF198cZ/FrqNjR7GiHbD29m2p\nzm5t3ZrafA5d7e3boqa+fzQMqUpldtYe92muE+/Pz9I2K9XtVaq5SlV7+7aoahgS1UOHpTbf/fjx\ntbdvi4aGo2Lo0ObU5u9te7W3b4sh9UfFsCHFz5a1+7GUleq+dCnl2lfJS+UYu507d8b27dsjImLH\njh3xs5/9LI499tg0ogAAAGReKu/Ybd68Oa688sooKyuLfD4fEydOjDPOOCONKAAAAJmXSrEbNmxY\nPProo2mMBgAA6HNSO90BAAAAB4diBwAAkHGKHQAAQMYpdgAAABmX2nnsoFTl8/nI5damMnvEiJFR\nUVGRymwA4OCyT0ExKXbwIbnc2vj3h2ZGY92Aos7duHlHnDttQTQ3O6cjAPQFudza+K/7X46m2uFF\nnbu+bV3En4R9ikOMYgc9aKwbEE1HVKUdAwDIuKba4XF0Y3PaMTgEOMYOAAAg4xQ7AACAjFPsAAAA\nMk6xAwAAyDjFDgAAIOMUOwAAgIxzuoNDgJNjAgBA36bYHQJyubXx0r9cEcNqi3vC7TfadkRc8o9O\njgkAAAWm2B0ihtUOiKMbqtOOAQAAFIBj7AAAADJOsQMAAMg4xQ4AACDjFDsAAICMU+wAAAAyTrED\nAADIOKc7APqkfD4fudza1OaPGDEyKioqUpsPZJf1CzgQih3QJ+Vya2Pe0pkxqKF/0Wdv2bQzrj9/\nQTQ3H1v02UD25XJr43//aE0MbhxW9NkdG9+I//W5sH5BBil2QJ81qKF/DB5alXYMgI9scOOwqBva\nnHYMIEMcYwcAAJBxih0AAEDGKXYAAAAZp9gBAABknGIHAACQcYodAABAxil2AAAAGZfJ89jl8/nI\n5damMnvEiJFRUVGRyuy+xv340dheFFKaj68Ij7GDxf0I9IZ9ir4pk8Uul1sbrz/wwziqtr6oc19v\na4348heiufnYos7tq3K5tfHzB/9nDKnrX9S5b23eGfHFuzN3P+Zya2Ph//kfUV9f3O3V2rozLrzo\nu5nbXnw0udzauOpHd8WAxsFFn71jY0d8+3NXeowdBLnc2rjmsf8bAxoaij57x6ZNMf/zf+R+hAzI\n5dbGa/eujuE1w4o6d137GxF/FtaJAslksYuIOKq2Ppobh6Qdg49pSF3/GN5YnXaMzKiv7x9HHFGV\ndgz6qAGNg6NqaHFfMOPgG9DQENVDm9KOAZS44TXDorn+6LRjcBA5xg4AACDjFDsAAICMS63YrVix\nIs4777yYMGFCLFiwIK0YAAAAmZdKsevq6oq5c+fGvffeG4899lgsXbo0Xn311TSiAAAAZF4qxW71\n6tVx1FFHRVNTU/Tr1y/OP//8aGlpSSMKAABA5qVS7DZu3BhDhvz3N1o2NjbGpk2b0ogCAACQeZk9\n3cHrba2pzDxqP9dZ19ZRlCwfnjliP9d5o21HMaLsMfO4/Vznrc07i5LlwzNH7Oc6GzcXf3v1ZmZr\na/G3V29mtqeQqzczt2wqfq7ezN2xaWuRkny0uTs2Fn/96s3cnZs2FynJR5u7c1Pxfw/1Zu6OlF4o\n3d/c7ZveKlKSnuYev4+fry9emD3mDt3rzzs2vlG8MHvM/b29/nzTpteLF2aPucfs8zpvtRY/21ut\nr0dz7PucbOvb1hUpzQdnDo5R+7zOuvbiP8bWtb8RR8e+z5e6rv03RUrzwZkjYuS+r9O2sUhpPjhz\nf93jd5UlSZIULM1ePP/88/Htb3877r333oiI7i9PmTlzZrGjAAAAZF4qH8U84YQTYt26dbF+/frY\ntWtXLF26NMaPH59GFAAAgMxL5aOYFRUV8bWvfS1mzJgRSZLEhRdeGM3NzWlEAQAAyLxUPooJAADA\nwZPaCcoBAAA4OBQ7AACAjFPsAAAAMi6z57E7ECtWrIhbb701kiSJqVOnlszpFebMmRPLly+P2tra\nWLJkSdpxuu3atSu+/OUvx+7duyOfz8eECRPiyiuvTDtWRER0dXXF1KlTo7GxMb7zne+kHafbuHHj\norq6OsrLy6OysjIWLlyYdqR47bXXYvbs2VFWVhZJksQbb7wRV199dVxyySVpR4v77rsvFi5cGGVl\nZTFq1Ki47bbb4rDDDit6jp6eg//2b/8Wd911V7z66quxcOHCOP74vZ8Hq5i5IiK+//3vxw9+8IOo\nrKyMs846K7761a+mnmvNmjXx9a9/Pd59992orKyMr3/963HCCScUNdeGDRvi+uuvj7a2tigvL4+L\nLrooLrnkktiyZUvMnj071q9fH0ceeWTMnz8/Bg4cmHqutB9jH841bdq0uPjii2PevHnxk5/8JA47\n7LAYPnx43HbbbVFdXZ16rr//+7+PlpaWKC8vj9ra2vjmN78Z9fX1qeV6/3583z//8z/HvHnzYtWq\nVXH44YeXRK4014q93Y+zZ8+OXC4XERFbtmyJQYMGxeLFi1PL9f72WrNmTXzjG9+IHTt2RFNTU3zr\nW9+KqqqqouXa2z5X2uvX3nKVwpofsef+YNrb63dzTZkyJY444oj4zne+U7z1PjlE5PP55Oyzz07e\nfPPNZNeuXckf/dEfJa+88krasZIkSZJf/vKXya9+9avk85//fNpR9rBjx44kSZKks7Mzueiii5IX\nXngh5UTv+d73vpdce+21yZ//+Z+nHeUDxo0bl7z99ttpx9irfD6fjBkzJvnNb36TdpRkw4YNybhx\n45J33303SZIkufrqq5PFixenkqWn5+Crr76avPbaa8nFF1+c/Nd//VfJ5Fq1alUyffr0ZPfu3UmS\nJElbW1tJ5JoxY0by1FNPJUmSJMuXL0/+5E/+pOi5Nm3alPzqV79KkiRJtm3blpx77rnJK6+8ksyb\nNy9ZsGBBkiRJcs899yS33357SeRK+zG2t1xPP/10ks/nkyRJkttvvz351re+VRK5tm3b1n2df/mX\nf0n+6q/+qiRyJUmSvPXWW8mMGTOSz3zmM0lHR0dJ5Ep7rdjX9nrfN7/5zeQf//EfU801YcKE5JVX\nXkmmTp2a/PKXv0ySJEkefvjhZP78+UXNlSQ973OlvX71lOv5558viTU/SfbcHyyF7dVTrmKt94fM\nRzFXr14dRx11VDQ1NUW/fv3i/PPPj5aWlrRjRUTEySefHJ/85CfTjtGj/v37R8R7r9h0dnamnOY9\nGzZsiJ/+9Kdx0UUXpR1lD0mSRFdXV9ox9mrlypUxfPjwGDJkSNpRIuK9V7R27twZnZ2d8c4770RD\nQ0MqOXp6Do4cOTJGjBgRSYpfHNxTrgcffDAuu+yyqKx87wMXNTU1JZGrrKwstm7dGhERW7dujcbG\nxqLnqq+vj+OOOy4iIqqqqqK5uTk2btwYLS0tMXny5IiImDx5cixbtiz1XJs2bUr9Mba3XKeffnqU\nl7+3e3DSSSfFhg0bSiLX7757snPnzu6MaeeKiLj11lvj+uuvL2qe/eVKe63Y1/Z6349//OP4/Oc/\nn2qukSNHxsaNG+P111+Pk08+OSIiTj/99Pj3f//3ouaK6HmfK+31q6dcZWVlJbHm97Q/WArbq6dc\nxVrvD5lit3Hjxg/szDY2Nu6xwLCnrq6umDRpUowZMybGjBkTJ554YtqRun+BlpWVpR1lD2VlZTFj\nxoyYOnVqPPTQQ2nH2cOPfvSjOP/889OOERHvPQenT58eY8eOjTPPPDMGDhwYp59+etqxSl4ul4tn\nn322+2NNL774YtqRIiLixhtvjHnz5sXYsWPj9ttvj2uvvTbVPG+++WasWbMmRo8eHW1tbVFXVxcR\n7+3Utbe3p56rFNbS37W3XAsXLowzzzwzpVR75rrzzjtj7NixsWTJkpg1a1ZJ5GppaYkhQ4bEpz71\nqdTy9JSrlNaKnh5fzz77bNTV1cXw4cNTzzV69Og45phjul/w//GPf1z0FzQiet7nKoX1q6dcpbDm\n97Q/WArbK8391EOm2HFgysvL45FHHokVK1bECy+8EK+88kqqeZYvXx51dXVx3HHHpfpOyt48+OCD\nsXjx4vinf/qneOCBB+LZZ59NO1K33bt3x5NPPhmf/exn044SERG//e1vo6WlJX7yk5/EU089FTt2\n7CipY0xLVT6fjy1btsRDDz0U1113XVxzzTVpR4qI9x77N910UyxfvjxuvPHGmDNnTmpZtm/fHrNm\nzYo5c+ZEVVXVHr9c03pR6MO5SsXect19993Rr1+/mDhxYsnkmj17dixfvjwmTpwY999/f+q5Kioq\n4p577omrrrqq++dp/W768PYqlbVib4+vxx57rOjv1u0r1y233BI/+MEPYurUqbFjx47o169f0TP9\n7j7X6tWr49e//nVJrF895Up7ze/t/mCxt1fa+6mHTLFrbGyM3/zmN91/37hxY2of+8qi6urqOPXU\nU+Opp55KNcd//Md/xJNPPhnjx4+Pa6+9Np555pnUPv7Sk/cfUzU1NXHOOeeUzLspEe99edDxxx+f\nykf3erJy5coYNmxYHH744VFRURHnnHNO/Od//mfasUreEUccEeeee25ERJx44olRXl4eHR0dKaeK\neOSRR+Lss8+OiIjzzjsvVq9enUqOzs7OmDVrVlxwwQXdeWpra2Pz5s0REdHa2prKc6CnXKVgb7kW\nLVoUP/34h09GAAAD20lEQVTpT+OOO+4oqVzvmzhxYioflftwrnXr1sX69evjggsuiHHjxsXGjRtj\n6tSp0dbWlmquiNJYK/Z2P+bz+XjiiSdSe6Gxp1wjR46Me++9Nx5++OE4//zzU30nsbq6Ok455ZR4\n6qmnSmL96inXo48+muqa39P+4HXXXRd1dXWpbq+091MPmWJ3wgkndC/Au3btiqVLl8b48ePTjtWt\nFN99am9v7/789DvvvBMrV66MkSNHpprpK1/5SixfvjxaWlri7/7u7+LUU0+NefPmpZrpfTt37ozt\n27dHRMSOHTviZz/7WRx77LEpp/pvS5cuTfXV0Q8bOnRovPDCC/Huu+9GkiSxatWqaG5uTi3Pvp6D\naT4/Pzz77LPPjlWrVkXEe9942tnZGYMHD049V2NjY/ziF7+IiIif//znMWLEiKJninjvGzuPOeaY\nuPTSS7svGzduXCxatCgiIhYvXpzK2t9Trt+V1mOsp1wrVqyIe++9N+6+++5UvqV2b7lef/317j8v\nW7Ysld9HH841atSoePrpp6OlpSWefPLJaGxsjMWLF0dtbW2quSJKY63Y2+P+6aefjpEjR6ZyXNbe\ncr3/kb2urq64++674wtf+EJRM/W0z9Xc3Jz6+rW3XA0NDamu+T3tD95+++3xmc98JtXt1Zv91EKu\n94fM6Q4qKiria1/7WsyYMSOSJIkLL7ww1Z3I3/V+o3/77bdj7NixcdVVV8XUqVPTjhWtra1xww03\nRFdXV3R1dcXnPve5OOuss9KOVbI2b94cV155ZZSVlUU+n4+JEyfGGWeckXasiHivdK5cuTJuvvnm\ntKN0O/HEE2PChAkxadKkqKysjN///d+PadOmpZKlp+fgoEGDYu7cudHR0RGXX355/N7v/V5897vf\nTT3X1KlT48Ybb4yJEydGv3794m//9m+LmmlvuebOnRt/8zd/E11dXfGJT3wi5s6dW/Rczz33XCxZ\nsiRGjRoVkyZNirKyspg9e3Zcdtllcc0118TDDz8cTU1NMX/+/JLItWvXrlQfYz3luuaaa+KWW26J\n3bt3x4wZMyIiYvTo0fGNb3wj1VyzZ8+OhQsXxmuvvRbl5eUxdOjQ+Ou//uuiZdpXrt89BvH908qU\nQq4pU6bEnDlzUlsr9rW90vjSlP3lyuVy8cADD0RZWVmce+65MWXKlKLm2ts+1+jRo1Ndv/aWq7q6\nOm655ZZU1/yezJw5M9XttTfLli0rynpflpTiW0UAAAD02iHzUUwAAIC+SrEDAADIOMUOAAAg4xQ7\nAACAjFPsAAAAMk6xAwAAyDjFDgAAIOMUOwAAgIz7f1zh1s7aQ9OrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f27218c7588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3wAAAE7CAYAAACG1oPfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n86E1PcEzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2721dbd5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "print(np.sum(corr_pred == 0))\n",
    "wrong_pred_indexes = np.argwhere(corr_pred == 0)\n",
    "plt.figure(figsize = (15,5))\n",
    "sns.countplot(y_valid[corr_pred == 0])\n",
    "plt.figure(figsize = (15,5))\n",
    "sns.countplot(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Let me augment the undersampled data and see what happens"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
