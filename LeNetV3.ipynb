{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet for Traffic Sign V3\n",
    "![LeNet Architecture](lenet.png)\n",
    "Modified from source: Yan LeCun\n",
    "\n",
    "Author: Peng \"Patrick\" Su\n",
    "Testing hist_eq\n",
    "\n",
    "Since augmentation does not help at all, V3 is used as submitted version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load the traffic sign data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "\n",
    "training_file = '../traffic-signs-data/train.p'\n",
    "validation_file = '../traffic-signs-data/valid.p'\n",
    "testing_file = '../traffic-signs-data/test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The traffic sign data comes as 32x32x3 images, and LeNet accepts 32x32xC images. No need to pad anything. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "Shuffle the training data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    return (img - 128.)/128.\n",
    "def hist_eq(img):\n",
    "    if (len(img.shape)>3): # if you're passing in a collection of images\n",
    "        num_images = img.shape[0]\n",
    "        image_shape = img.shape[1:]\n",
    "        locEqImg = np.zeros([num_images,image_shape[0],image_shape[1],image_shape[2]])\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(6,6))\n",
    "        for i in range(num_images):\n",
    "            #print(\"currImg dtype is \", img[i].dtype)\n",
    "            #img[i] =img[i].astype(np.float32)\n",
    "            currImg = img[i].squeeze()\n",
    "            #img_yuv = cv2.cvtColor(currImg, cv2.COLOR_RGB2YUV)\n",
    "            #img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "            #tmp = cv2.cvtColor(img_yuv, cv 2.COLOR_YUV2RGB)\n",
    "            #eqImg[i]=tmp\n",
    "            \n",
    "            img_lab = cv2.cvtColor(currImg, cv2.COLOR_RGB2LAB)\n",
    "            img_lab[:,:,0]=clahe.apply(img_lab[:,:,0])\n",
    "            tmp = cv2.cvtColor(img_lab, cv2.COLOR_LAB2RGB)\n",
    "            locEqImg[i] = tmp\n",
    "    else:\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(6,6))\n",
    "        img_lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "        img_lab[:,:,0]=clahe.apply(img_lab[:,:,0])\n",
    "        tmp = cv2.cvtColor(img_lab, cv2.COLOR_LAB2RGB)\n",
    "        locEqImg = tmp\n",
    "    return locEqImg\n",
    "\n",
    "X_train = hist_eq(X_train)\n",
    "X_train = normalize(X_train)\n",
    "X_train = X_train.astype('float32')\n",
    "\n",
    "X_valid = hist_eq(X_valid)\n",
    "X_valid = normalize(X_valid)\n",
    "X_valid = X_valid.astype('float32')\n",
    "\n",
    "X_test = hist_eq(X_test)\n",
    "X_test = normalize(X_test)\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34799, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup TensorFlow\n",
    "The `EPOCH` and `BATCH_SIZE` values affect the training speed and model accuracy.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Implement LeNet-5\n",
    "Implement the [LeNet-5](http://yann.lecun.com/exdb/lenet/) neural network architecture.\n",
    "\n",
    "This is the only cell you need to edit.\n",
    "### Input\n",
    "The LeNet architecture accepts a 32x32xC image as input, where C is the number of color channels. Since MNIST images are grayscale, C is 1 in this case.\n",
    "\n",
    "### Architecture\n",
    "**Layer 1: Convolutional.** The output shape should be 28x28x6.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 14x14x6.\n",
    "\n",
    "**Layer 2: Convolutional.** The output shape should be 10x10x16.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 5x5x16.\n",
    "\n",
    "**Flatten.** Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. The easiest way to do is by using `tf.contrib.layers.flatten`, which is already imported for you.\n",
    "\n",
    "**Layer 3: Fully Connected.** This should have 120 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 4: Fully Connected.** This should have 84 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 5: Fully Connected (Logits).** This should have 10 outputs.\n",
    "\n",
    "### Output\n",
    "Return the result of the 2nd fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    weights = {\n",
    "        'wc1': tf.Variable(tf.truncated_normal([5,5,3,6], mu, sigma)),\n",
    "        'wc2': tf.Variable(tf.truncated_normal([5,5,6,16], mu, sigma)),\n",
    "        'wf3': tf.Variable(tf.truncated_normal([5*5*16, 120], mu, sigma)),\n",
    "        'wf4': tf.Variable(tf.truncated_normal([120, 84], mu, sigma)),\n",
    "        'wf5': tf.Variable(tf.truncated_normal([84, 43], mu, sigma))}\n",
    "    biases = {\n",
    "        'bc1': tf.zeros([6]),\n",
    "        'bc2': tf.zeros([16]),\n",
    "        'bf3': tf.zeros([120]),\n",
    "        'bf4': tf.zeros([84]),\n",
    "        'bf5': tf.zeros([43]),\n",
    "    }\n",
    "    # TODO: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    conv1 = tf.nn.conv2d(x, weights['wc1'], strides = [1, 1, 1, 1], padding = 'VALID')\n",
    "    conv1 = tf.nn.bias_add(conv1, biases['bc1'])\n",
    "    # TODO: Activation.\n",
    "    conv1 = tf.nn.relu(conv1)    \n",
    "    # TODO: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'VALID')\n",
    "    conv1 = tf.nn.dropout(conv1, keep_prob)\n",
    "#     flat1 = flatten(conv1, [-1, 14*14*6])\n",
    "    \n",
    "    # TODO: Layer 2: Convolutional. Output = 10x10x16.\n",
    "    conv2 = tf.nn.conv2d(conv1, weights['wc2'], strides = [1, 1, 1, 1], padding = 'VALID')\n",
    "    conv2 = tf.nn.bias_add(conv2, biases['bc2'])    \n",
    "    # TODO: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    # TODO: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'VALID')\n",
    "    conv2 = tf.nn.dropout(conv2, keep_prob)\n",
    "    # TODO: Flatten. Input = 5x5x8. Output = 200.\n",
    "\n",
    "#     flat2 = flatten(conv2, [-1, 5*5*16])\n",
    "#     flat = tf.concat(1, [flat1, flat2])\n",
    "    \n",
    "    flat = flatten(conv2, [-1, 5*5*16])\n",
    "    \n",
    "    # TODO: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    fc3 = tf.add(tf.matmul(flat, weights['wf3']), biases['bf3'])\n",
    "    # TODO: Activation.\n",
    "    fc3 = tf.nn.relu(fc3)\n",
    "    # TODO: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc4 = tf.add(tf.matmul(fc3, weights['wf4']), biases['bf4'])\n",
    "    # TODO: Activation.\n",
    "    fc4 = tf.nn.relu(fc4)\n",
    "    # TODO: Layer 5: Fully Connected. Input = 84. Output = 43.\n",
    "    logits = tf.add(tf.matmul(fc4, weights['wf5']), biases['bf5'])\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Labels\n",
    "Train LeNet to classify traffic sign data.\n",
    "\n",
    "`x` is a placeholder for a batch of input images.\n",
    "`y` is a placeholder for a batch of output labels.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 43)\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline\n",
    "Create a training pipeline that uses the model to classify MNIST data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rate = 0.001\n",
    "logits = LeNet(x)\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluate how well the loss and accuracy of the model for a given dataset.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    total_loss = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        loss, accuracy = sess.run([loss_operation, accuracy_operation], feed_dict={x: batch_x, y: batch_y, keep_prob:1.0})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "        total_loss += (loss * len(batch_x))\n",
    "    return total_loss / num_examples, total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "Run the training data through the training pipeline to train the model.\n",
    "\n",
    "Before each epoch, shuffle the training set.\n",
    "\n",
    "After each epoch, measure the loss and accuracy of the validation set.\n",
    "\n",
    "Save the model after training.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "save_dir = 'LeNetV3'\n",
    "out_dir = out_dir = os.path.abspath(os.path.join(os.path.curdir, \"../Traffic-Sign-Classifier-runs\", save_dir))\n",
    "\n",
    "train_summary_dir = os.path.join(out_dir, \"train\")        \n",
    "valid_summary_dir = os.path.join(out_dir, \"valid\")\n",
    "checkpoint_dir = os.path.join(out_dir, \"checkpoints\")\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir,\"model\")\n",
    "checkpoint_every = 100\n",
    "train_summary_every = 100\n",
    "valid_summary_every = 100\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "Batch 100 Train Loss: 1.119 Train Accuracy: 0.656\n",
      "\n",
      "valid writing\n",
      "EPOCH 1 Batch 100 ...\n",
      "Validation loss = 1.197\n",
      "Validation Accuracy = 0.639\n",
      "\n",
      "Batch 200 Train Loss: 0.420 Train Accuracy: 0.859\n",
      "\n",
      "valid writing\n",
      "EPOCH 1 Batch 200 ...\n",
      "Validation loss = 0.565\n",
      "Validation Accuracy = 0.832\n",
      "\n",
      "Batch 300 Train Loss: 0.259 Train Accuracy: 0.922\n",
      "\n",
      "valid writing\n",
      "EPOCH 2 Batch 300 ...\n",
      "Validation loss = 0.384\n",
      "Validation Accuracy = 0.888\n",
      "\n",
      "Batch 400 Train Loss: 0.264 Train Accuracy: 0.945\n",
      "\n",
      "valid writing\n",
      "EPOCH 2 Batch 400 ...\n",
      "Validation loss = 0.376\n",
      "Validation Accuracy = 0.885\n",
      "\n",
      "Batch 500 Train Loss: 0.175 Train Accuracy: 0.953\n",
      "\n",
      "valid writing\n",
      "EPOCH 2 Batch 500 ...\n",
      "Validation loss = 0.308\n",
      "Validation Accuracy = 0.907\n",
      "\n",
      "Batch 600 Train Loss: 0.186 Train Accuracy: 0.945\n",
      "\n",
      "valid writing\n",
      "EPOCH 3 Batch 600 ...\n",
      "Validation loss = 0.268\n",
      "Validation Accuracy = 0.923\n",
      "\n",
      "Batch 700 Train Loss: 0.068 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 3 Batch 700 ...\n",
      "Validation loss = 0.250\n",
      "Validation Accuracy = 0.920\n",
      "\n",
      "Batch 800 Train Loss: 0.102 Train Accuracy: 0.984\n",
      "\n",
      "valid writing\n",
      "EPOCH 3 Batch 800 ...\n",
      "Validation loss = 0.249\n",
      "Validation Accuracy = 0.928\n",
      "\n",
      "Batch 900 Train Loss: 0.091 Train Accuracy: 0.984\n",
      "\n",
      "valid writing\n",
      "EPOCH 4 Batch 900 ...\n",
      "Validation loss = 0.204\n",
      "Validation Accuracy = 0.947\n",
      "\n",
      "Batch 1000 Train Loss: 0.115 Train Accuracy: 0.977\n",
      "\n",
      "valid writing\n",
      "EPOCH 4 Batch 1000 ...\n",
      "Validation loss = 0.222\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "Batch 1100 Train Loss: 0.041 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 5 Batch 1100 ...\n",
      "Validation loss = 0.243\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "Batch 1200 Train Loss: 0.115 Train Accuracy: 0.969\n",
      "\n",
      "valid writing\n",
      "EPOCH 5 Batch 1200 ...\n",
      "Validation loss = 0.196\n",
      "Validation Accuracy = 0.950\n",
      "\n",
      "Batch 1300 Train Loss: 0.055 Train Accuracy: 0.984\n",
      "\n",
      "valid writing\n",
      "EPOCH 5 Batch 1300 ...\n",
      "Validation loss = 0.180\n",
      "Validation Accuracy = 0.946\n",
      "\n",
      "Batch 1400 Train Loss: 0.067 Train Accuracy: 0.984\n",
      "\n",
      "valid writing\n",
      "EPOCH 6 Batch 1400 ...\n",
      "Validation loss = 0.173\n",
      "Validation Accuracy = 0.954\n",
      "\n",
      "Batch 1500 Train Loss: 0.035 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 6 Batch 1500 ...\n",
      "Validation loss = 0.196\n",
      "Validation Accuracy = 0.945\n",
      "\n",
      "Batch 1600 Train Loss: 0.017 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 6 Batch 1600 ...\n",
      "Validation loss = 0.167\n",
      "Validation Accuracy = 0.949\n",
      "\n",
      "Batch 1700 Train Loss: 0.019 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 7 Batch 1700 ...\n",
      "Validation loss = 0.168\n",
      "Validation Accuracy = 0.954\n",
      "\n",
      "Batch 1800 Train Loss: 0.022 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 7 Batch 1800 ...\n",
      "Validation loss = 0.169\n",
      "Validation Accuracy = 0.953\n",
      "\n",
      "Batch 1900 Train Loss: 0.029 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 7 Batch 1900 ...\n",
      "Validation loss = 0.178\n",
      "Validation Accuracy = 0.956\n",
      "\n",
      "Batch 2000 Train Loss: 0.023 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 8 Batch 2000 ...\n",
      "Validation loss = 0.166\n",
      "Validation Accuracy = 0.954\n",
      "\n",
      "Batch 2100 Train Loss: 0.047 Train Accuracy: 0.984\n",
      "\n",
      "valid writing\n",
      "EPOCH 8 Batch 2100 ...\n",
      "Validation loss = 0.163\n",
      "Validation Accuracy = 0.958\n",
      "\n",
      "Batch 2200 Train Loss: 0.006 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 9 Batch 2200 ...\n",
      "Validation loss = 0.162\n",
      "Validation Accuracy = 0.953\n",
      "\n",
      "Batch 2300 Train Loss: 0.014 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 9 Batch 2300 ...\n",
      "Validation loss = 0.176\n",
      "Validation Accuracy = 0.957\n",
      "\n",
      "Batch 2400 Train Loss: 0.071 Train Accuracy: 0.977\n",
      "\n",
      "valid writing\n",
      "EPOCH 9 Batch 2400 ...\n",
      "Validation loss = 0.203\n",
      "Validation Accuracy = 0.950\n",
      "\n",
      "Batch 2500 Train Loss: 0.004 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 10 Batch 2500 ...\n",
      "Validation loss = 0.175\n",
      "Validation Accuracy = 0.954\n",
      "\n",
      "Batch 2600 Train Loss: 0.026 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 10 Batch 2600 ...\n",
      "Validation loss = 0.157\n",
      "Validation Accuracy = 0.959\n",
      "\n",
      "Batch 2700 Train Loss: 0.016 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 10 Batch 2700 ...\n",
      "Validation loss = 0.180\n",
      "Validation Accuracy = 0.955\n",
      "\n",
      "Batch 2800 Train Loss: 0.013 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 11 Batch 2800 ...\n",
      "Validation loss = 0.178\n",
      "Validation Accuracy = 0.956\n",
      "\n",
      "Batch 2900 Train Loss: 0.028 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 11 Batch 2900 ...\n",
      "Validation loss = 0.194\n",
      "Validation Accuracy = 0.952\n",
      "\n",
      "Batch 3000 Train Loss: 0.012 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 12 Batch 3000 ...\n",
      "Validation loss = 0.168\n",
      "Validation Accuracy = 0.960\n",
      "\n",
      "Batch 3100 Train Loss: 0.012 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 12 Batch 3100 ...\n",
      "Validation loss = 0.173\n",
      "Validation Accuracy = 0.962\n",
      "\n",
      "Batch 3200 Train Loss: 0.032 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 12 Batch 3200 ...\n",
      "Validation loss = 0.184\n",
      "Validation Accuracy = 0.955\n",
      "\n",
      "Batch 3300 Train Loss: 0.010 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 13 Batch 3300 ...\n",
      "Validation loss = 0.172\n",
      "Validation Accuracy = 0.957\n",
      "\n",
      "Batch 3400 Train Loss: 0.016 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 13 Batch 3400 ...\n",
      "Validation loss = 0.171\n",
      "Validation Accuracy = 0.961\n",
      "\n",
      "Batch 3500 Train Loss: 0.064 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 13 Batch 3500 ...\n",
      "Validation loss = 0.168\n",
      "Validation Accuracy = 0.959\n",
      "\n",
      "Batch 3600 Train Loss: 0.019 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 14 Batch 3600 ...\n",
      "Validation loss = 0.144\n",
      "Validation Accuracy = 0.964\n",
      "\n",
      "Batch 3700 Train Loss: 0.019 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 14 Batch 3700 ...\n",
      "Validation loss = 0.182\n",
      "Validation Accuracy = 0.957\n",
      "\n",
      "Batch 3800 Train Loss: 0.058 Train Accuracy: 0.977\n",
      "\n",
      "valid writing\n",
      "EPOCH 14 Batch 3800 ...\n",
      "Validation loss = 0.162\n",
      "Validation Accuracy = 0.955\n",
      "\n",
      "Batch 3900 Train Loss: 0.012 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 15 Batch 3900 ...\n",
      "Validation loss = 0.216\n",
      "Validation Accuracy = 0.950\n",
      "\n",
      "Batch 4000 Train Loss: 0.007 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 15 Batch 4000 ...\n",
      "Validation loss = 0.148\n",
      "Validation Accuracy = 0.962\n",
      "\n",
      "Batch 4100 Train Loss: 0.008 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 16 Batch 4100 ...\n",
      "Validation loss = 0.164\n",
      "Validation Accuracy = 0.962\n",
      "\n",
      "Batch 4200 Train Loss: 0.023 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 16 Batch 4200 ...\n",
      "Validation loss = 0.174\n",
      "Validation Accuracy = 0.961\n",
      "\n",
      "Batch 4300 Train Loss: 0.005 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 16 Batch 4300 ...\n",
      "Validation loss = 0.178\n",
      "Validation Accuracy = 0.958\n",
      "\n",
      "Batch 4400 Train Loss: 0.007 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 17 Batch 4400 ...\n",
      "Validation loss = 0.196\n",
      "Validation Accuracy = 0.963\n",
      "\n",
      "Batch 4500 Train Loss: 0.011 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 17 Batch 4500 ...\n",
      "Validation loss = 0.169\n",
      "Validation Accuracy = 0.961\n",
      "\n",
      "Batch 4600 Train Loss: 0.004 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 17 Batch 4600 ...\n",
      "Validation loss = 0.172\n",
      "Validation Accuracy = 0.959\n",
      "\n",
      "Batch 4700 Train Loss: 0.019 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 18 Batch 4700 ...\n",
      "Validation loss = 0.179\n",
      "Validation Accuracy = 0.965\n",
      "\n",
      "Batch 4800 Train Loss: 0.003 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 18 Batch 4800 ...\n",
      "Validation loss = 0.198\n",
      "Validation Accuracy = 0.957\n",
      "\n",
      "Batch 4900 Train Loss: 0.005 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 19 Batch 4900 ...\n",
      "Validation loss = 0.189\n",
      "Validation Accuracy = 0.956\n",
      "\n",
      "Batch 5000 Train Loss: 0.003 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 19 Batch 5000 ...\n",
      "Validation loss = 0.138\n",
      "Validation Accuracy = 0.966\n",
      "\n",
      "Batch 5100 Train Loss: 0.031 Train Accuracy: 0.984\n",
      "\n",
      "valid writing\n",
      "EPOCH 19 Batch 5100 ...\n",
      "Validation loss = 0.164\n",
      "Validation Accuracy = 0.962\n",
      "\n",
      "Batch 5200 Train Loss: 0.004 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 20 Batch 5200 ...\n",
      "Validation loss = 0.143\n",
      "Validation Accuracy = 0.966\n",
      "\n",
      "Batch 5300 Train Loss: 0.012 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 20 Batch 5300 ...\n",
      "Validation loss = 0.169\n",
      "Validation Accuracy = 0.961\n",
      "\n",
      "Batch 5400 Train Loss: 0.041 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 20 Batch 5400 ...\n",
      "Validation loss = 0.152\n",
      "Validation Accuracy = 0.967\n",
      "\n",
      "Training Done\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(out_dir):\n",
    "    shutil.rmtree(out_dir)\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    global_step = 0\n",
    "    train_summary_writer = tf.summary.FileWriter(train_summary_dir, sess.graph)\n",
    "    valid_summary_writer = tf.summary.FileWriter(valid_summary_dir, sess.graph)\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob:0.8})\n",
    "            global_step += 1\n",
    "            if global_step % train_summary_every == 0:\n",
    "                train_loss, train_accuracy = evaluate(batch_x, batch_y)\n",
    "                train_summaries = tf.Summary()\n",
    "                train_summaries.value.add(tag='Train Loss', simple_value=train_loss)\n",
    "                train_summaries.value.add(tag='Train Accuracy', simple_value=train_accuracy)\n",
    "                train_summary_writer.add_summary(train_summaries, global_step)\n",
    "                print(\"Batch {} Train Loss: {:.3f} Train Accuracy: {:.3f}\".format(global_step, train_loss, train_accuracy))\n",
    "                print()\n",
    "            if global_step % valid_summary_every == 0:\n",
    "                validation_loss, validation_accuracy = evaluate(X_valid, y_valid)\n",
    "                valid_summaries = tf.Summary()\n",
    "                valid_summaries.value.add(tag='Validation Loss', simple_value=validation_loss)\n",
    "                valid_summaries.value.add(tag='Validation Accuracy', simple_value=validation_accuracy)\n",
    "                print(\"valid writing\")\n",
    "                valid_summary_writer.add_summary(valid_summaries, global_step)\n",
    "                print(\"EPOCH {} Batch {} ...\".format(i+1, global_step))\n",
    "                print(\"Validation loss = {:.3f}\".format(validation_loss))\n",
    "                print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "                print()\n",
    "            if global_step % checkpoint_every == 0:\n",
    "                saver.save(sess, checkpoint_prefix, global_step=global_step)            \n",
    "    print(\"Training Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "Once you are completely satisfied with your model, evaluate the performance of the model on the test set.\n",
    "\n",
    "Be sure to only do this once!\n",
    "\n",
    "If you were to measure the performance of your trained model on the test set, then improve your model, and then measure the performance of your model on the test set again, that would invalidate your test results. You wouldn't get a true measure of how well your model would perform against real data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.007\n",
      "Train Accuracy = 0.999\n",
      "Valid Loss = 0.152\n",
      "Valid Accuracy = 0.967\n",
      "Test Loss = 0.175\n",
      "Test Accuracy = 0.956\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    train_loss, train_accuracy = evaluate(X_train, y_train)\n",
    "    print(\"Train Loss = {:.3f}\".format(train_loss))\n",
    "    print(\"Train Accuracy = {:.3f}\".format(train_accuracy))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    valid_loss, valid_accuracy = evaluate(X_valid, y_valid)\n",
    "    print(\"Valid Loss = {:.3f}\".format(valid_loss))\n",
    "    print(\"Valid Accuracy = {:.3f}\".format(valid_accuracy))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    test_loss, test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Loss = {:.3f}\".format(test_loss))\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4410, 32, 32, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corr_predict(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    corr_predict = np.zeros(num_examples)\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        temp = np.array(sess.run([correct_prediction], feed_dict={x: batch_x, y: batch_y, keep_prob:1.0})).astype('Int32')\n",
    "        corr_predict[offset:offset+BATCH_SIZE] = temp\n",
    "    return corr_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    corr_pred = corr_predict(X_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fce488ddf98>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3YAAAE7CAYAAACR9BMWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFDsAAICMU+wAAAAy7v8DO965OaiIL6kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fce20ebd128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4IAAAE7CAYAAACIUz/1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIDN/D9ThSN371ZumAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcea44695f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "print(np.sum(corr_pred == 0))\n",
    "wrong_pred_indexes = np.argwhere(corr_pred == 0)\n",
    "plt.figure(figsize = (15,5))\n",
    "sns.countplot(y_valid[corr_pred == 0])\n",
    "plt.figure(figsize = (15,5))\n",
    "sns.countplot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Let me augment the undersampled data and see what happens"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
