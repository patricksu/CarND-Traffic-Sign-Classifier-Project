{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet for Traffic Sign V2\n",
    "![LeNet Architecture](lenet.png)\n",
    "Modified from source: Yan LeCun\n",
    "\n",
    "Author: Peng \"Patrick\" Su\n",
    "\n",
    "Testing Stage1 + Stage2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load the traffic sign data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "\n",
    "training_file = '../traffic-signs-data/train.p'\n",
    "validation_file = '../traffic-signs-data/valid.p'\n",
    "testing_file = '../traffic-signs-data/test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The traffic sign data comes as 32x32x3 images, and LeNet accepts 32x32xC images. No need to pad anything. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "Shuffle the training data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    return (img - 128.)/128.\n",
    "def gray(img):\n",
    "    if len(img.shape) > 3:\n",
    "        ans = []\n",
    "        for ig in img:\n",
    "            ans.append(cv2.cvtColor(ig, cv2.COLOR_RGB2GRAY))\n",
    "        return np.array(ans)\n",
    "    else:\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "X_train = gray(X_train)\n",
    "X_train = normalize(X_train)\n",
    "X_train = X_train.astype('float32')\n",
    "X_train = np.expand_dims(X_train, 3)\n",
    "\n",
    "X_valid = gray(X_valid)\n",
    "X_valid = normalize(X_valid)\n",
    "X_valid = X_valid.astype('float32')\n",
    "X_valid = np.expand_dims(X_valid, 3)\n",
    "\n",
    "X_test = gray(X_test)\n",
    "X_test = normalize(X_test)\n",
    "X_test = X_test.astype('float32')\n",
    "X_test = np.expand_dims(X_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34799, 32, 32, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup TensorFlow\n",
    "The `EPOCH` and `BATCH_SIZE` values affect the training speed and model accuracy.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Implement LeNet-5\n",
    "Implement the [LeNet-5](http://yann.lecun.com/exdb/lenet/) neural network architecture.\n",
    "\n",
    "This is the only cell you need to edit.\n",
    "### Input\n",
    "The LeNet architecture accepts a 32x32xC image as input, where C is the number of color channels. Since MNIST images are grayscale, C is 1 in this case.\n",
    "\n",
    "### Architecture\n",
    "**Layer 1: Convolutional.** The output shape should be 28x28x6.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 14x14x6.\n",
    "\n",
    "**Layer 2: Convolutional.** The output shape should be 10x10x16.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 5x5x16.\n",
    "\n",
    "**Flatten.** Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. The easiest way to do is by using `tf.contrib.layers.flatten`, which is already imported for you.\n",
    "\n",
    "**Layer 3: Fully Connected.** This should have 120 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 4: Fully Connected.** This should have 84 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 5: Fully Connected (Logits).** This should have 10 outputs.\n",
    "\n",
    "### Output\n",
    "Return the result of the 2nd fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    weights = {\n",
    "        'wc1': tf.Variable(tf.truncated_normal([5,5,1,6], mu, sigma)),\n",
    "        'wc2': tf.Variable(tf.truncated_normal([5,5,6,16], mu, sigma)),\n",
    "        'wf3': tf.Variable(tf.truncated_normal([5*5*16+14*14*6, 120], mu, sigma)),\n",
    "        'wf4': tf.Variable(tf.truncated_normal([120, 84], mu, sigma)),\n",
    "        'wf5': tf.Variable(tf.truncated_normal([84, 43], mu, sigma))}\n",
    "    biases = {\n",
    "        'bc1': tf.zeros([6]),\n",
    "        'bc2': tf.zeros([16]),\n",
    "        'bf3': tf.zeros([120]),\n",
    "        'bf4': tf.zeros([84]),\n",
    "        'bf5': tf.zeros([43]),\n",
    "    }\n",
    "    # TODO: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    conv1 = tf.nn.conv2d(x, weights['wc1'], strides = [1, 1, 1, 1], padding = 'VALID')\n",
    "    conv1 = tf.nn.bias_add(conv1, biases['bc1'])\n",
    "    # TODO: Activation.\n",
    "    conv1 = tf.nn.relu(conv1)    \n",
    "    # TODO: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'VALID')\n",
    "    conv1 = tf.nn.dropout(conv1, keep_prob)\n",
    "    flat1 = flatten(conv1, [-1, 14*14*6])\n",
    "    \n",
    "    # TODO: Layer 2: Convolutional. Output = 10x10x16.\n",
    "    conv2 = tf.nn.conv2d(conv1, weights['wc2'], strides = [1, 1, 1, 1], padding = 'VALID')\n",
    "    conv2 = tf.nn.bias_add(conv2, biases['bc2'])    \n",
    "    # TODO: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    # TODO: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'VALID')\n",
    "    conv2 = tf.nn.dropout(conv2, keep_prob)\n",
    "    # TODO: Flatten. Input = 5x5x8. Output = 200.\n",
    "\n",
    "    flat2 = flatten(conv2, [-1, 5*5*16])\n",
    "    flat = tf.concat(1, [flat1, flat2])\n",
    "\n",
    "    # TODO: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    fc3 = tf.add(tf.matmul(flat, weights['wf3']), biases['bf3'])\n",
    "    # TODO: Activation.\n",
    "    fc3 = tf.nn.relu(fc3)\n",
    "    # TODO: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc4 = tf.add(tf.matmul(fc3, weights['wf4']), biases['bf4'])\n",
    "    # TODO: Activation.\n",
    "    fc4 = tf.nn.relu(fc4)\n",
    "    # TODO: Layer 5: Fully Connected. Input = 84. Output = 43.\n",
    "    logits = tf.add(tf.matmul(fc4, weights['wf5']), biases['bf5'])\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Labels\n",
    "Train LeNet to classify traffic sign data.\n",
    "\n",
    "`x` is a placeholder for a batch of input images.\n",
    "`y` is a placeholder for a batch of output labels.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 43)\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline\n",
    "Create a training pipeline that uses the model to classify MNIST data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rate = 0.001\n",
    "logits = LeNet(x)\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluate how well the loss and accuracy of the model for a given dataset.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    total_loss = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        loss, accuracy = sess.run([loss_operation, accuracy_operation], feed_dict={x: batch_x, y: batch_y, keep_prob:1.0})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "        total_loss += (loss * len(batch_x))\n",
    "    return total_loss / num_examples, total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "Run the training data through the training pipeline to train the model.\n",
    "\n",
    "Before each epoch, shuffle the training set.\n",
    "\n",
    "After each epoch, measure the loss and accuracy of the validation set.\n",
    "\n",
    "Save the model after training.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "Batch 100 Train Loss: 1.925 Train Accuracy: 0.391\n",
      "\n",
      "valid writing\n",
      "EPOCH 1 Batch 100 ...\n",
      "Validation loss = 2.088\n",
      "Validation Accuracy = 0.420\n",
      "\n",
      "Batch 200 Train Loss: 0.988 Train Accuracy: 0.734\n",
      "\n",
      "valid writing\n",
      "EPOCH 1 Batch 200 ...\n",
      "Validation loss = 1.148\n",
      "Validation Accuracy = 0.688\n",
      "\n",
      "Batch 300 Train Loss: 0.492 Train Accuracy: 0.891\n",
      "\n",
      "valid writing\n",
      "EPOCH 2 Batch 300 ...\n",
      "Validation loss = 0.822\n",
      "Validation Accuracy = 0.776\n",
      "\n",
      "Batch 400 Train Loss: 0.425 Train Accuracy: 0.867\n",
      "\n",
      "valid writing\n",
      "EPOCH 2 Batch 400 ...\n",
      "Validation loss = 0.642\n",
      "Validation Accuracy = 0.827\n",
      "\n",
      "Batch 500 Train Loss: 0.210 Train Accuracy: 0.977\n",
      "\n",
      "valid writing\n",
      "EPOCH 2 Batch 500 ...\n",
      "Validation loss = 0.559\n",
      "Validation Accuracy = 0.855\n",
      "\n",
      "Batch 600 Train Loss: 0.315 Train Accuracy: 0.875\n",
      "\n",
      "valid writing\n",
      "EPOCH 3 Batch 600 ...\n",
      "Validation loss = 0.533\n",
      "Validation Accuracy = 0.859\n",
      "\n",
      "Batch 700 Train Loss: 0.163 Train Accuracy: 0.969\n",
      "\n",
      "valid writing\n",
      "EPOCH 3 Batch 700 ...\n",
      "Validation loss = 0.477\n",
      "Validation Accuracy = 0.882\n",
      "\n",
      "Batch 800 Train Loss: 0.162 Train Accuracy: 0.969\n",
      "\n",
      "valid writing\n",
      "EPOCH 3 Batch 800 ...\n",
      "Validation loss = 0.439\n",
      "Validation Accuracy = 0.889\n",
      "\n",
      "Batch 900 Train Loss: 0.097 Train Accuracy: 0.977\n",
      "\n",
      "valid writing\n",
      "EPOCH 4 Batch 900 ...\n",
      "Validation loss = 0.425\n",
      "Validation Accuracy = 0.895\n",
      "\n",
      "Batch 1000 Train Loss: 0.149 Train Accuracy: 0.969\n",
      "\n",
      "valid writing\n",
      "EPOCH 4 Batch 1000 ...\n",
      "Validation loss = 0.407\n",
      "Validation Accuracy = 0.901\n",
      "\n",
      "Batch 1100 Train Loss: 0.088 Train Accuracy: 0.977\n",
      "\n",
      "valid writing\n",
      "EPOCH 5 Batch 1100 ...\n",
      "Validation loss = 0.393\n",
      "Validation Accuracy = 0.903\n",
      "\n",
      "Batch 1200 Train Loss: 0.091 Train Accuracy: 0.977\n",
      "\n",
      "valid writing\n",
      "EPOCH 5 Batch 1200 ...\n",
      "Validation loss = 0.409\n",
      "Validation Accuracy = 0.901\n",
      "\n",
      "Batch 1300 Train Loss: 0.076 Train Accuracy: 0.984\n",
      "\n",
      "valid writing\n",
      "EPOCH 5 Batch 1300 ...\n",
      "Validation loss = 0.396\n",
      "Validation Accuracy = 0.904\n",
      "\n",
      "Batch 1400 Train Loss: 0.069 Train Accuracy: 0.977\n",
      "\n",
      "valid writing\n",
      "EPOCH 6 Batch 1400 ...\n",
      "Validation loss = 0.386\n",
      "Validation Accuracy = 0.907\n",
      "\n",
      "Batch 1500 Train Loss: 0.073 Train Accuracy: 0.984\n",
      "\n",
      "valid writing\n",
      "EPOCH 6 Batch 1500 ...\n",
      "Validation loss = 0.434\n",
      "Validation Accuracy = 0.889\n",
      "\n",
      "Batch 1600 Train Loss: 0.059 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 6 Batch 1600 ...\n",
      "Validation loss = 0.346\n",
      "Validation Accuracy = 0.920\n",
      "\n",
      "Batch 1700 Train Loss: 0.058 Train Accuracy: 0.984\n",
      "\n",
      "valid writing\n",
      "EPOCH 7 Batch 1700 ...\n",
      "Validation loss = 0.387\n",
      "Validation Accuracy = 0.908\n",
      "\n",
      "Batch 1800 Train Loss: 0.089 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 7 Batch 1800 ...\n",
      "Validation loss = 0.338\n",
      "Validation Accuracy = 0.918\n",
      "\n",
      "Batch 1900 Train Loss: 0.033 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 7 Batch 1900 ...\n",
      "Validation loss = 0.415\n",
      "Validation Accuracy = 0.913\n",
      "\n",
      "Batch 2000 Train Loss: 0.037 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 8 Batch 2000 ...\n",
      "Validation loss = 0.406\n",
      "Validation Accuracy = 0.905\n",
      "\n",
      "Batch 2100 Train Loss: 0.025 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 8 Batch 2100 ...\n",
      "Validation loss = 0.371\n",
      "Validation Accuracy = 0.918\n",
      "\n",
      "Batch 2200 Train Loss: 0.040 Train Accuracy: 0.984\n",
      "\n",
      "valid writing\n",
      "EPOCH 9 Batch 2200 ...\n",
      "Validation loss = 0.395\n",
      "Validation Accuracy = 0.916\n",
      "\n",
      "Batch 2300 Train Loss: 0.016 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 9 Batch 2300 ...\n",
      "Validation loss = 0.409\n",
      "Validation Accuracy = 0.911\n",
      "\n",
      "Batch 2400 Train Loss: 0.032 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 9 Batch 2400 ...\n",
      "Validation loss = 0.445\n",
      "Validation Accuracy = 0.897\n",
      "\n",
      "Batch 2500 Train Loss: 0.019 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 10 Batch 2500 ...\n",
      "Validation loss = 0.429\n",
      "Validation Accuracy = 0.903\n",
      "\n",
      "Batch 2600 Train Loss: 0.025 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 10 Batch 2600 ...\n",
      "Validation loss = 0.356\n",
      "Validation Accuracy = 0.924\n",
      "\n",
      "Batch 2700 Train Loss: 0.013 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 10 Batch 2700 ...\n",
      "Validation loss = 0.371\n",
      "Validation Accuracy = 0.915\n",
      "\n",
      "Batch 2800 Train Loss: 0.046 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 11 Batch 2800 ...\n",
      "Validation loss = 0.335\n",
      "Validation Accuracy = 0.924\n",
      "\n",
      "Batch 2900 Train Loss: 0.015 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 11 Batch 2900 ...\n",
      "Validation loss = 0.388\n",
      "Validation Accuracy = 0.918\n",
      "\n",
      "Batch 3000 Train Loss: 0.018 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 12 Batch 3000 ...\n",
      "Validation loss = 0.374\n",
      "Validation Accuracy = 0.917\n",
      "\n",
      "Batch 3100 Train Loss: 0.027 Train Accuracy: 0.984\n",
      "\n",
      "valid writing\n",
      "EPOCH 12 Batch 3100 ...\n",
      "Validation loss = 0.346\n",
      "Validation Accuracy = 0.924\n",
      "\n",
      "Batch 3200 Train Loss: 0.011 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 12 Batch 3200 ...\n",
      "Validation loss = 0.348\n",
      "Validation Accuracy = 0.920\n",
      "\n",
      "Batch 3300 Train Loss: 0.093 Train Accuracy: 0.984\n",
      "\n",
      "valid writing\n",
      "EPOCH 13 Batch 3300 ...\n",
      "Validation loss = 0.409\n",
      "Validation Accuracy = 0.914\n",
      "\n",
      "Batch 3400 Train Loss: 0.019 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 13 Batch 3400 ...\n",
      "Validation loss = 0.419\n",
      "Validation Accuracy = 0.909\n",
      "\n",
      "Batch 3500 Train Loss: 0.018 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 13 Batch 3500 ...\n",
      "Validation loss = 0.367\n",
      "Validation Accuracy = 0.917\n",
      "\n",
      "Batch 3600 Train Loss: 0.027 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 14 Batch 3600 ...\n",
      "Validation loss = 0.440\n",
      "Validation Accuracy = 0.907\n",
      "\n",
      "Batch 3700 Train Loss: 0.029 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 14 Batch 3700 ...\n",
      "Validation loss = 0.368\n",
      "Validation Accuracy = 0.925\n",
      "\n",
      "Batch 3800 Train Loss: 0.048 Train Accuracy: 0.977\n",
      "\n",
      "valid writing\n",
      "EPOCH 14 Batch 3800 ...\n",
      "Validation loss = 0.390\n",
      "Validation Accuracy = 0.920\n",
      "\n",
      "Batch 3900 Train Loss: 0.006 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 15 Batch 3900 ...\n",
      "Validation loss = 0.399\n",
      "Validation Accuracy = 0.916\n",
      "\n",
      "Batch 4000 Train Loss: 0.003 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 15 Batch 4000 ...\n",
      "Validation loss = 0.509\n",
      "Validation Accuracy = 0.913\n",
      "\n",
      "Batch 4100 Train Loss: 0.019 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 16 Batch 4100 ...\n",
      "Validation loss = 0.431\n",
      "Validation Accuracy = 0.917\n",
      "\n",
      "Batch 4200 Train Loss: 0.020 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 16 Batch 4200 ...\n",
      "Validation loss = 0.355\n",
      "Validation Accuracy = 0.926\n",
      "\n",
      "Batch 4300 Train Loss: 0.008 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 16 Batch 4300 ...\n",
      "Validation loss = 0.359\n",
      "Validation Accuracy = 0.924\n",
      "\n",
      "Batch 4400 Train Loss: 0.011 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 17 Batch 4400 ...\n",
      "Validation loss = 0.394\n",
      "Validation Accuracy = 0.923\n",
      "\n",
      "Batch 4500 Train Loss: 0.003 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 17 Batch 4500 ...\n",
      "Validation loss = 0.427\n",
      "Validation Accuracy = 0.922\n",
      "\n",
      "Batch 4600 Train Loss: 0.007 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 17 Batch 4600 ...\n",
      "Validation loss = 0.402\n",
      "Validation Accuracy = 0.907\n",
      "\n",
      "Batch 4700 Train Loss: 0.010 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 18 Batch 4700 ...\n",
      "Validation loss = 0.403\n",
      "Validation Accuracy = 0.921\n",
      "\n",
      "Batch 4800 Train Loss: 0.017 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 18 Batch 4800 ...\n",
      "Validation loss = 0.341\n",
      "Validation Accuracy = 0.921\n",
      "\n",
      "Batch 4900 Train Loss: 0.014 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 19 Batch 4900 ...\n",
      "Validation loss = 0.462\n",
      "Validation Accuracy = 0.905\n",
      "\n",
      "Batch 5000 Train Loss: 0.012 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 19 Batch 5000 ...\n",
      "Validation loss = 0.397\n",
      "Validation Accuracy = 0.915\n",
      "\n",
      "Batch 5100 Train Loss: 0.015 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 19 Batch 5100 ...\n",
      "Validation loss = 0.376\n",
      "Validation Accuracy = 0.921\n",
      "\n",
      "Batch 5200 Train Loss: 0.005 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 20 Batch 5200 ...\n",
      "Validation loss = 0.359\n",
      "Validation Accuracy = 0.925\n",
      "\n",
      "Batch 5300 Train Loss: 0.007 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 20 Batch 5300 ...\n",
      "Validation loss = 0.353\n",
      "Validation Accuracy = 0.927\n",
      "\n",
      "Batch 5400 Train Loss: 0.005 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 20 Batch 5400 ...\n",
      "Validation loss = 0.388\n",
      "Validation Accuracy = 0.927\n",
      "\n",
      "Batch 5500 Train Loss: 0.008 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 21 Batch 5500 ...\n",
      "Validation loss = 0.428\n",
      "Validation Accuracy = 0.920\n",
      "\n",
      "Batch 5600 Train Loss: 0.008 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 21 Batch 5600 ...\n",
      "Validation loss = 0.376\n",
      "Validation Accuracy = 0.925\n",
      "\n",
      "Batch 5700 Train Loss: 0.002 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 21 Batch 5700 ...\n",
      "Validation loss = 0.377\n",
      "Validation Accuracy = 0.923\n",
      "\n",
      "Batch 5800 Train Loss: 0.022 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 22 Batch 5800 ...\n",
      "Validation loss = 0.545\n",
      "Validation Accuracy = 0.900\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5900 Train Loss: 0.006 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 22 Batch 5900 ...\n",
      "Validation loss = 0.411\n",
      "Validation Accuracy = 0.927\n",
      "\n",
      "Batch 6000 Train Loss: 0.005 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 23 Batch 6000 ...\n",
      "Validation loss = 0.391\n",
      "Validation Accuracy = 0.927\n",
      "\n",
      "Batch 6100 Train Loss: 0.011 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 23 Batch 6100 ...\n",
      "Validation loss = 0.440\n",
      "Validation Accuracy = 0.919\n",
      "\n",
      "Batch 6200 Train Loss: 0.003 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 23 Batch 6200 ...\n",
      "Validation loss = 0.463\n",
      "Validation Accuracy = 0.922\n",
      "\n",
      "Batch 6300 Train Loss: 0.003 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 24 Batch 6300 ...\n",
      "Validation loss = 0.396\n",
      "Validation Accuracy = 0.922\n",
      "\n",
      "Batch 6400 Train Loss: 0.004 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 24 Batch 6400 ...\n",
      "Validation loss = 0.472\n",
      "Validation Accuracy = 0.914\n",
      "\n",
      "Batch 6500 Train Loss: 0.037 Train Accuracy: 0.977\n",
      "\n",
      "valid writing\n",
      "EPOCH 24 Batch 6500 ...\n",
      "Validation loss = 0.419\n",
      "Validation Accuracy = 0.919\n",
      "\n",
      "Batch 6600 Train Loss: 0.009 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 25 Batch 6600 ...\n",
      "Validation loss = 0.367\n",
      "Validation Accuracy = 0.927\n",
      "\n",
      "Batch 6700 Train Loss: 0.001 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 25 Batch 6700 ...\n",
      "Validation loss = 0.405\n",
      "Validation Accuracy = 0.924\n",
      "\n",
      "Batch 6800 Train Loss: 0.001 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 25 Batch 6800 ...\n",
      "Validation loss = 0.367\n",
      "Validation Accuracy = 0.931\n",
      "\n",
      "Batch 6900 Train Loss: 0.027 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 26 Batch 6900 ...\n",
      "Validation loss = 0.438\n",
      "Validation Accuracy = 0.918\n",
      "\n",
      "Batch 7000 Train Loss: 0.010 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 26 Batch 7000 ...\n",
      "Validation loss = 0.459\n",
      "Validation Accuracy = 0.919\n",
      "\n",
      "Batch 7100 Train Loss: 0.007 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 27 Batch 7100 ...\n",
      "Validation loss = 0.403\n",
      "Validation Accuracy = 0.926\n",
      "\n",
      "Batch 7200 Train Loss: 0.005 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 27 Batch 7200 ...\n",
      "Validation loss = 0.513\n",
      "Validation Accuracy = 0.924\n",
      "\n",
      "Batch 7300 Train Loss: 0.006 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 27 Batch 7300 ...\n",
      "Validation loss = 0.432\n",
      "Validation Accuracy = 0.927\n",
      "\n",
      "Batch 7400 Train Loss: 0.002 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 28 Batch 7400 ...\n",
      "Validation loss = 0.456\n",
      "Validation Accuracy = 0.921\n",
      "\n",
      "Batch 7500 Train Loss: 0.001 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 28 Batch 7500 ...\n",
      "Validation loss = 0.477\n",
      "Validation Accuracy = 0.922\n",
      "\n",
      "Batch 7600 Train Loss: 0.020 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 28 Batch 7600 ...\n",
      "Validation loss = 0.577\n",
      "Validation Accuracy = 0.917\n",
      "\n",
      "Batch 7700 Train Loss: 0.003 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 29 Batch 7700 ...\n",
      "Validation loss = 0.570\n",
      "Validation Accuracy = 0.916\n",
      "\n",
      "Batch 7800 Train Loss: 0.002 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 29 Batch 7800 ...\n",
      "Validation loss = 0.562\n",
      "Validation Accuracy = 0.908\n",
      "\n",
      "Batch 7900 Train Loss: 0.001 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 30 Batch 7900 ...\n",
      "Validation loss = 0.444\n",
      "Validation Accuracy = 0.926\n",
      "\n",
      "Batch 8000 Train Loss: 0.000 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 30 Batch 8000 ...\n",
      "Validation loss = 0.686\n",
      "Validation Accuracy = 0.907\n",
      "\n",
      "Batch 8100 Train Loss: 0.029 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 30 Batch 8100 ...\n",
      "Validation loss = 0.558\n",
      "Validation Accuracy = 0.916\n",
      "\n",
      "Batch 8200 Train Loss: 0.001 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 31 Batch 8200 ...\n",
      "Validation loss = 0.475\n",
      "Validation Accuracy = 0.919\n",
      "\n",
      "Batch 8300 Train Loss: 0.003 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 31 Batch 8300 ...\n",
      "Validation loss = 0.464\n",
      "Validation Accuracy = 0.925\n",
      "\n",
      "Batch 8400 Train Loss: 0.003 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 31 Batch 8400 ...\n",
      "Validation loss = 0.443\n",
      "Validation Accuracy = 0.927\n",
      "\n",
      "Batch 8500 Train Loss: 0.004 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 32 Batch 8500 ...\n",
      "Validation loss = 0.418\n",
      "Validation Accuracy = 0.925\n",
      "\n",
      "Batch 8600 Train Loss: 0.004 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 32 Batch 8600 ...\n",
      "Validation loss = 0.466\n",
      "Validation Accuracy = 0.921\n",
      "\n",
      "Batch 8700 Train Loss: 0.007 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 32 Batch 8700 ...\n",
      "Validation loss = 0.440\n",
      "Validation Accuracy = 0.925\n",
      "\n",
      "Batch 8800 Train Loss: 0.004 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 33 Batch 8800 ...\n",
      "Validation loss = 0.461\n",
      "Validation Accuracy = 0.922\n",
      "\n",
      "Batch 8900 Train Loss: 0.001 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 33 Batch 8900 ...\n",
      "Validation loss = 0.413\n",
      "Validation Accuracy = 0.926\n",
      "\n",
      "Batch 9000 Train Loss: 0.004 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 34 Batch 9000 ...\n",
      "Validation loss = 0.426\n",
      "Validation Accuracy = 0.920\n",
      "\n",
      "Batch 9100 Train Loss: 0.005 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 34 Batch 9100 ...\n",
      "Validation loss = 0.495\n",
      "Validation Accuracy = 0.923\n",
      "\n",
      "Batch 9200 Train Loss: 0.003 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 34 Batch 9200 ...\n",
      "Validation loss = 0.480\n",
      "Validation Accuracy = 0.922\n",
      "\n",
      "Batch 9300 Train Loss: 0.004 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 35 Batch 9300 ...\n",
      "Validation loss = 0.389\n",
      "Validation Accuracy = 0.929\n",
      "\n",
      "Batch 9400 Train Loss: 0.002 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 35 Batch 9400 ...\n",
      "Validation loss = 0.420\n",
      "Validation Accuracy = 0.930\n",
      "\n",
      "Batch 9500 Train Loss: 0.006 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 35 Batch 9500 ...\n",
      "Validation loss = 0.529\n",
      "Validation Accuracy = 0.920\n",
      "\n",
      "Batch 9600 Train Loss: 0.003 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 36 Batch 9600 ...\n",
      "Validation loss = 0.484\n",
      "Validation Accuracy = 0.927\n",
      "\n",
      "Batch 9700 Train Loss: 0.001 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 36 Batch 9700 ...\n",
      "Validation loss = 0.484\n",
      "Validation Accuracy = 0.921\n",
      "\n",
      "Batch 9800 Train Loss: 0.002 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 37 Batch 9800 ...\n",
      "Validation loss = 0.413\n",
      "Validation Accuracy = 0.931\n",
      "\n",
      "Batch 9900 Train Loss: 0.000 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 37 Batch 9900 ...\n",
      "Validation loss = 0.453\n",
      "Validation Accuracy = 0.930\n",
      "\n",
      "Batch 10000 Train Loss: 0.020 Train Accuracy: 0.992\n",
      "\n",
      "valid writing\n",
      "EPOCH 37 Batch 10000 ...\n",
      "Validation loss = 0.431\n",
      "Validation Accuracy = 0.926\n",
      "\n",
      "Batch 10100 Train Loss: 0.000 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 38 Batch 10100 ...\n",
      "Validation loss = 0.558\n",
      "Validation Accuracy = 0.917\n",
      "\n",
      "Batch 10200 Train Loss: 0.000 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 38 Batch 10200 ...\n",
      "Validation loss = 0.516\n",
      "Validation Accuracy = 0.927\n",
      "\n",
      "Batch 10300 Train Loss: 0.001 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 38 Batch 10300 ...\n",
      "Validation loss = 0.370\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "Batch 10400 Train Loss: 0.000 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 39 Batch 10400 ...\n",
      "Validation loss = 0.500\n",
      "Validation Accuracy = 0.921\n",
      "\n",
      "Batch 10500 Train Loss: 0.000 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 39 Batch 10500 ...\n",
      "Validation loss = 0.368\n",
      "Validation Accuracy = 0.933\n",
      "\n",
      "Batch 10600 Train Loss: 0.003 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 39 Batch 10600 ...\n",
      "Validation loss = 0.417\n",
      "Validation Accuracy = 0.923\n",
      "\n",
      "Batch 10700 Train Loss: 0.001 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 40 Batch 10700 ...\n",
      "Validation loss = 0.495\n",
      "Validation Accuracy = 0.918\n",
      "\n",
      "Batch 10800 Train Loss: 0.001 Train Accuracy: 1.000\n",
      "\n",
      "valid writing\n",
      "EPOCH 40 Batch 10800 ...\n",
      "Validation loss = 0.486\n",
      "Validation Accuracy = 0.919\n",
      "\n",
      "Training Done\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "save_dir = 'LeNetV2'\n",
    "out_dir = out_dir = os.path.abspath(os.path.join(os.path.curdir, \"../Traffic-Sign-Classifier-runs\", save_dir))\n",
    "if os.path.exists(out_dir):\n",
    "    shutil.rmtree(out_dir)\n",
    "train_summary_dir = os.path.join(out_dir, \"train\")        \n",
    "valid_summary_dir = os.path.join(out_dir, \"valid\")\n",
    "checkpoint_dir = os.path.join(out_dir, \"checkpoints\")\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir,\"model\")\n",
    "checkpoint_every = 100\n",
    "train_summary_every = 100\n",
    "valid_summary_every = 100\n",
    "\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    global_step = 0\n",
    "    train_summary_writer = tf.summary.FileWriter(train_summary_dir, sess.graph)\n",
    "    valid_summary_writer = tf.summary.FileWriter(valid_summary_dir, sess.graph)\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob:0.8})\n",
    "            global_step += 1\n",
    "            if global_step % train_summary_every == 0:\n",
    "                train_loss, train_accuracy = evaluate(batch_x, batch_y)\n",
    "                train_summaries = tf.Summary()\n",
    "                train_summaries.value.add(tag='Train Loss', simple_value=train_loss)\n",
    "                train_summaries.value.add(tag='Train Accuracy', simple_value=train_accuracy)\n",
    "                train_summary_writer.add_summary(train_summaries, global_step)\n",
    "                print(\"Batch {} Train Loss: {:.3f} Train Accuracy: {:.3f}\".format(global_step, train_loss, train_accuracy))\n",
    "                print()\n",
    "            if global_step % valid_summary_every == 0:\n",
    "                validation_loss, validation_accuracy = evaluate(X_valid, y_valid)\n",
    "                valid_summaries = tf.Summary()\n",
    "                valid_summaries.value.add(tag='Validation Loss', simple_value=validation_loss)\n",
    "                valid_summaries.value.add(tag='Validation Accuracy', simple_value=validation_accuracy)\n",
    "                print(\"valid writing\")\n",
    "                valid_summary_writer.add_summary(valid_summaries, global_step)\n",
    "                print(\"EPOCH {} Batch {} ...\".format(i+1, global_step))\n",
    "                print(\"Validation loss = {:.3f}\".format(validation_loss))\n",
    "                print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "                print()\n",
    "            if global_step % checkpoint_every == 0:\n",
    "                saver.save(sess, checkpoint_prefix, global_step=global_step)            \n",
    "    print(\"Training Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "Once you are completely satisfied with your model, evaluate the performance of the model on the test set.\n",
    "\n",
    "Be sure to only do this once!\n",
    "\n",
    "If you were to measure the performance of your trained model on the test set, then improve your model, and then measure the performance of your model on the test set again, that would invalidate your test results. You wouldn't get a true measure of how well your model would perform against real data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.010\n",
      "Train Accuracy = 0.998\n",
      "Valid Loss = 0.341\n",
      "Valid Accuracy = 0.921\n",
      "Test Loss = 0.519\n",
      "Test Accuracy = 0.920\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "    train_loss, train_accuracy = evaluate(X_train, y_train)\n",
    "    print(\"Train Loss = {:.3f}\".format(train_loss))\n",
    "    print(\"Train Accuracy = {:.3f}\".format(train_accuracy))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "    valid_loss, valid_accuracy = evaluate(X_valid, y_valid)\n",
    "    print(\"Valid Loss = {:.3f}\".format(valid_loss))\n",
    "    print(\"Valid Accuracy = {:.3f}\".format(valid_accuracy))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "    test_loss, test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Loss = {:.3f}\".format(test_loss))\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
